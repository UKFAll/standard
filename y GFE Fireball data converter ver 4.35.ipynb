{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meteor observation converter\n",
    "This notebook converts fireball observations to the Global Fireball Exchange (GFE) format or between camera formats, including from UFOAnalyzer (UFO), FRIPON, RMS, CAMS, MetRec, AllSkyCams and Desert Fireball Network (DFN) formats.  \n",
    "\n",
    "It will prompt for an input file which must be in one of the following formats:\n",
    "-  GFE, an astropy extended CSV table with a filename ending in .ECSV.\n",
    "-  UFO, an XML file with a filename ending in A.XML; or\n",
    "-  DFN/GFO, an astropy extended CSV table, with a filename ending in .ECSV.\n",
    "-  RMS, an FTP_Detect file ending in .txt\n",
    "-  CAMS, an FTP_Detect file ending in .txt\n",
    "-  FRIPON/SCAMP, a Pixmet file ending in .met\n",
    "-  MetRec, a file ending in *.inf \n",
    "-  All Sky Cams, a JSON data file.\n",
    "\n",
    "Once read, the coordinate data will be used to populate an Astropy Table object in a standard format. \n",
    "\n",
    "The user then selects which format to write to.  A filename is suggested but the user can alter this.  Depending on the output chosen, the files written are for:\n",
    "-  GFE, an .ECSV file. \n",
    "-  UFO, an A.XML and a .CSV file in UFO R91 format for use in UFOOrbit;  \n",
    "-  DFN, an .ECSV file. \n",
    "-  FRIPON/SCAMP, a .MET file.\n",
    "-  All Sky Cams, a .JSON file.\n",
    "-  Excel, a .CSV file with date/time converted to Excel format\n",
    "\n",
    "Thi script was written by (and is maintained by) Jim Rowe of the UK Fireball Alliance, www.ukfall.org.uk. Thanks to Hadrien Devillepoix of DFN for providing the DFN Read/write code which is incorporated in altered form into this notebook.  Thanks also to Nicholas Pochinkov of Dunsink Observatory, Dublin, for substantial development work done in June/July 2020.  RA/DEC Alt/Az conversion code is taken from RMS, copyright (c) 2016 Denis Vida.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installation of packages - the next line can be deleted after the first run on any particular machine\n",
    "! pip install mrg_core\n",
    "\n",
    "# MetRec conversion - https://mrg-tools.gitlab.io/mrg_core/doc/index.html\n",
    "from mrg_core.util.interfaces import MetRecInfFile\n",
    "from mrg_core.util.interfaces import MetRecLogFile\n",
    "\n",
    "# system packages\n",
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "#file handlers\n",
    "import xmltodict  #XML  - for UFOAnalyzer\n",
    "import json       #JSON - for RMS camera data and AllSkyCams files\n",
    "import csv\n",
    "\n",
    "#regular expressions\n",
    "import re as regex\n",
    "\n",
    "# date handling\n",
    "from datetime import datetime\n",
    "#from datetime import timedelta\n",
    "\n",
    "# numerical packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.table import Column\n",
    "from astropy.time import Time, TimeDelta\n",
    "from astropy.io import ascii\n",
    "\n",
    "#File opening controls\n",
    "from tkinter import filedialog \n",
    "from zipfile import ZipFile\n",
    "\n",
    "# definitions of constants:\n",
    "ISO_FORMAT = \"%Y-%m-%dT%H:%M:%S.%f\"  #defines a consistent iso date format\n",
    "RMS_DELAY = 2.4                      #seconds to subtract from all RMS date/times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UFOAnalyzer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ufo_to_std(ufo_1):\n",
    "    # This function takes a UFO file, passed as a nested dictionary, and returns a table in DFN format.\n",
    "    # UFO format is a deeply nested XML file. The nesting is:\n",
    "    # The whole XML is in the dictionary ufo_1\n",
    "    # ufoanalyzer_record  \"  \"  ufo_2 - a dictionary of station data\n",
    "    # ua2_objects         \"  \"  ufo_3 - intermediate, suppressed\n",
    "    # ua2_object          \"  \"  ufo_4 - a dictionary of observation metadata\n",
    "    # ua2_objpath         \"  \"  ufo_5 - intermediate, suppressed\n",
    "    # ua2_fdata2          \"  \"  ufo_6 - the dictionary of trajectory data\n",
    "    \n",
    "    # Note on UFO capture algorithm:\n",
    "    # Assuming head=30 and the video is interlaced 25 fps (so \n",
    "    # effectively 50 fps), the capture algorithm seems to be:\n",
    "    # 1. Event detected at time X.  This is used as the \n",
    "    #    timestamp and is recorded in the file.\n",
    "    # 2. Save the framestack from time X plus 30 full \n",
    "    #    frames (60 interlaced half-frames) beforehand\n",
    "    # 3. Now treat each of your half-frames as frames.  So \n",
    "    #    time X is frame 61.\n",
    "    # 4. Examine each frame from frame 1 to the end of the \n",
    "    #    frame stack to see whether the event started earlier \n",
    "    #    or later than you thought.  \n",
    "    # 5. Rather than frame 61, it can sometimes be frame 54, \n",
    "    #    or 59, or 64 when the first real event is detected.  \n",
    "    #    Save this as “fs”.\n",
    "    # 6. List all of the frames where you think you know what \n",
    "    #    happened, starting with fno=fs, and skipping frames \n",
    "    #    that can’t be analysed.  \n",
    "        \n",
    "     \n",
    "    ttt_list = []\n",
    "    ufo_2=ufo_1['ufoanalyzer_record']\n",
    "\n",
    "    ufo_4=ufo_2['ua2_objects']['ua2_object']\n",
    "    meteor_count = len(ufo_4)\n",
    "    if meteor_count > 10 :\n",
    "        # if ufo4 has 59 elements then it's a single meteor but the data is less nested\n",
    "        meteor_count = 1\n",
    "\n",
    "    # Now get metadata from ufo_2\n",
    "    \n",
    "    #location\n",
    "    obs_latitude = float(ufo_2['@lat'])\n",
    "    obs_longitude = float(ufo_2['@lng'])\n",
    "    obs_elevation = float(ufo_2['@alt'])\n",
    "    \n",
    "    #camera station site name\n",
    "    origin = \"UFOAnalyzer\" + '_Ver_'+ ufo_2['@u2']  # or other formal network names\n",
    "    location = ufo_2['@lid']\n",
    "    telescope = ufo_2['@sid']     #no spaces or special characters\n",
    "    camera_id = location + '_' + telescope\n",
    "\n",
    "    #observer and instrument\n",
    "    observer = ufo_2['@observer']\n",
    "    instrument = ufo_2['@cam']\n",
    "    comment = ufo_2['@memo']\n",
    "    cx = int(ufo_2['@cx'])\n",
    "    cy = int(ufo_2['@cy'])\n",
    "\n",
    "    image_file = ufo_2['@clip_name']+'.AVI'\n",
    "    astrometry_number_stars = int(ufo_2['@rstar'])\n",
    "    lens = ufo_2['@lens']\n",
    " \n",
    "    # calculate event timings - file timestamp\n",
    "    timestamp_str = ufo_2['@y'] + '-' + ufo_2['@mo'] + '-' + ufo_2['@d']\n",
    "    timestamp_str += 'T' + ufo_2['@h'] + ':' + ufo_2['@m'] + ':' + ufo_2['@s']\n",
    "    timestamp = Time(timestamp_str)\n",
    "\n",
    "    # frame rate and beginning and middle of clip\n",
    "    multiplier = 1 + int(ufo_2['@interlaced'])\n",
    "    head = int(ufo_2['@head']) * multiplier\n",
    "    tail = int(ufo_2['@tail']) * multiplier\n",
    "    frame_rate = float(ufo_2['@fps']) * multiplier\n",
    "    \n",
    "\n",
    "    # now loop through each meteor\n",
    "    \n",
    "    for k in range(meteor_count):\n",
    "    \n",
    "        if meteor_count == 1 :\n",
    "            ufo_5 = ufo_4\n",
    "        else:\n",
    "            ufo_5 = ufo_4[k]\n",
    "        \n",
    "        sec = float(ufo_5['@sec'])\n",
    "        nlines = int(ufo_5['@sN'])\n",
    "        ufo_6=ufo_5['ua2_objpath']['ua2_fdata2']\n",
    "    \n",
    "        no_frames = int(ufo_5['@fN'])+ head + tail\n",
    "        fs = int(ufo_5['@fs'])\n",
    "        exposure_time = (no_frames-1.0)/frame_rate\n",
    "        AVI_start_sec = -float(head)/frame_rate  \n",
    "        AVI_mid_sec =  exposure_time * 0.5 + AVI_start_sec\n",
    "        AVI_start_time = str(timestamp + timedelta(seconds=AVI_start_sec))\n",
    "        AVI_mid_time = str(timestamp + timedelta(seconds=AVI_mid_sec))  \n",
    "        timestamp_frame = head + 1      # The file timestamp is the first frame after the \"head\"\n",
    "        exposure_time = (no_frames - 1.0) / frame_rate \n",
    "    \n",
    "        fov_vert = 0.0\n",
    "        fov_horiz =float(ufo_2['@vx'])\n",
    "        if cx > 0:\n",
    "            fov_vert = fov_horiz * cy / cx\n",
    "    \n",
    "        # construction of the metadata dictionary\n",
    "        meta_dic = {'obs_latitude': obs_latitude,\n",
    "               'obs_longitude': obs_longitude,\n",
    "               'obs_elevation': obs_elevation,\n",
    "               'origin': origin,\n",
    "               'location': location,\n",
    "               'telescope': telescope,\n",
    "               'camera_id': camera_id,\n",
    "               'observer': observer,\n",
    "               'comment': comment,\n",
    "               'instrument': instrument,\n",
    "               'lens': lens,\n",
    "               'cx' : cx,     \n",
    "               'cy' : cy,     \n",
    "               'photometric_band' : 'Unknown',     \n",
    "               'image_file' : image_file,\n",
    "               'isodate_start_obs': AVI_start_time,   \n",
    "               'isodate_calib': AVI_mid_time,   \n",
    "               'exposure_time': exposure_time,   \n",
    "               'astrometry_number_stars' : astrometry_number_stars,\n",
    "               # 'photometric_zero_point': float(ufo_2['@mimMag']),    \n",
    "               # 'photometric_zero_point_uncertainty': 0.0,\n",
    "               'mag_label': 'mag',     \n",
    "               'no_frags': 1,\n",
    "               'obs_az': float(ufo_2['@az']),     \n",
    "               'obs_ev': float(ufo_2['@ev']),     \n",
    "               'obs_rot': float(ufo_2['@rot']),     \n",
    "               'fov_horiz': fov_horiz,     \n",
    "               'fov_vert': fov_vert,     \n",
    "               }\n",
    "\n",
    "        # initialise table\n",
    "        ttt = Table()        \n",
    "        #Update the table metadata\n",
    "        ttt.meta.update(meta_dic)   \n",
    "   \n",
    "        #create time and main data arrays\n",
    "        # Datetime is ISO 8601 UTC format\n",
    "        datetime_array = []\n",
    "    \n",
    "        # Azimuth are East of North, in degrees\n",
    "        azimuth_array = []\n",
    "        # Altitudes are geometric (not apparent) angles above the horizon, in degrees\n",
    "        altitude_array = []\n",
    "\n",
    "        # Magnitude\n",
    "        mag_array = []\n",
    " \n",
    "        # Right Ascension / Declination coordinates read from file\n",
    "        ra_array  = []\n",
    "        dec_array = []\n",
    "\n",
    "        for i in range(nlines):\n",
    "            obs=ufo_6[i]\n",
    "            az   = float(obs['@az'])\n",
    "            elev = float(obs['@ev'])\n",
    "            ra   = float(obs['@ra'])\n",
    "            dec = float(obs['@dec'])\n",
    "            mag = float(obs['@mag'])\n",
    "            obs_time = (int(obs['@fno']) - timestamp_frame)/frame_rate\n",
    "            time_stamp = str(timestamp + timedelta(seconds=obs_time))  \n",
    "            azimuth_array.append(az)\n",
    "            altitude_array.append(elev)\n",
    "            ra_array.append(ra)\n",
    "            dec_array.append(dec)\n",
    "            mag_array.append(mag)\n",
    "            datetime_array.append(time_stamp)\n",
    "        \n",
    "        ## Populate the table with the data created to date\n",
    "        # create columns\n",
    "        ttt['datetime'] = datetime_array\n",
    "        ttt['ra']  = ra_array  * u.degree\n",
    "        ttt['dec'] = dec_array * u.degree \n",
    "        ttt['azimuth'] = azimuth_array * u.degree\n",
    "        ttt['altitude'] = altitude_array * u.degree    \n",
    "        ttt['mag'] = mag_array \n",
    "        ttt['x_image'] = 0.0 \n",
    "        ttt['y_image'] = 0.0 \n",
    "    \n",
    "        # now add ttt to the array of tables\n",
    "        ttt_list.append(ttt)\n",
    "    \n",
    "    \n",
    "    return(ttt_list, meteor_count);\n",
    "\n",
    "\n",
    "\n",
    "def std_to_ufo(ttt):\n",
    "    # Given a table in Standard format, returns: \n",
    "    # -  an XML string which can be written as a UFO A.XML file; and\n",
    "    # -  a CSV string which can be written as a csv file. \n",
    "    # In order to preserve the exact A.XML format, hard-coded string handling is used.\n",
    "    \n",
    "    # work out the frame rate of the observations in the table.  \n",
    "    start_time = Time(ttt['datetime'][0])  \n",
    "    start_time_str = str(ttt['datetime'][0])  \n",
    "    nlines = len(ttt['datetime'])    \n",
    "    cumu_times = []\n",
    "    step_sizes = []\n",
    "    last_sec = 0.0\n",
    "    for i in range(nlines):\n",
    "        sec = get_secs(Time(ttt['datetime'][i]),start_time)\n",
    "        cumu_times.append(sec)\n",
    "        sec_rounded = sec\n",
    "        time_change = int(round(1000*(sec_rounded - last_sec),0))\n",
    "        if i>0 and (time_change not in step_sizes):\n",
    "            step_sizes.append(time_change)\n",
    "        last_sec = sec_rounded\n",
    "    \n",
    "    #now test for common framerates\n",
    "    # likely framerates are 20 (DFN), 25 (UFO) or 30 (FRIPON) fps\n",
    "    smallest = min(step_sizes)\n",
    "    if (smallest==33 or smallest == 34 or smallest == 66 or smallest == 67):\n",
    "        frame_rate = 30.0\n",
    "    elif (smallest >= 39 and smallest <= 41):\n",
    "        frame_rate = 25.0\n",
    "    elif (smallest >= 49 and smallest <= 51):\n",
    "        frame_rate = 20.0\n",
    "    else:\n",
    "        # non-standard framerate\n",
    "        # gcd is the greatest common divisor of all of the steps, in milliseconds.  \n",
    "        # Note - if gcd <= 10 it implies frame rate >= 100 fps, which is probably caused by a rounding error\n",
    "        gcd = array_gcd(step_sizes)\n",
    "        frame_rate = 1000.0/float(gcd)\n",
    "    frame_step = 1/frame_rate\n",
    "    \n",
    "     \n",
    "    #work out the head, tail and first frame number\n",
    "    head_sec = round(-get_secs(Time(ttt.meta['isodate_start_obs']),start_time),6)\n",
    "    head = int(round(head_sec / frame_step,0))\n",
    "    \n",
    "    fs = head + 1\n",
    "    fN = 1+int(round(sec/frame_step,0))\n",
    "    fe = fs + fN -1\n",
    "    sN = nlines\n",
    "    sec = round(sec, 4)\n",
    "    interlaced = 0\n",
    "    tz = 0   #UTC is hard-coded for now   \n",
    "    \n",
    "    # work out number of frames-equivalent and tail\n",
    "    mid_sec = round(head_sec + get_secs(Time(ttt.meta['isodate_calib']),start_time),6)\n",
    "    clip_sec = round(max(min(2*mid_sec,30.0),(fe-1)*frame_step),6)   #maximum clip length 30 seconds\n",
    "    frames = int(round(clip_sec/frame_step,0)) + 1\n",
    "    tail = max(0,frames - (head + fN))\n",
    "    frames = head + fN + tail\n",
    "\n",
    "    \n",
    "    # alt and azimuth numbers\n",
    "    ev1, ev2, az1, az2, ra1, ra2, dec1, dec2 = ufo_ra_dec_alt_az(ttt)    \n",
    "    if az1 < 180.0:  #azimuth written to CSV files is south-oriented\n",
    "        az1_csv = az1 + 180\n",
    "    else:\n",
    "        az1_csv = az1 - 180\n",
    "    if az2 < 180.0:  #azimuth written to CSV files is south-oriented\n",
    "        az2_csv = az2 + 180\n",
    "    else:\n",
    "        az2_csv = az2 - 180\n",
    "    \n",
    "    \n",
    "    # first write the csv string in UFOOrbit R91 format\n",
    "    csv_s = 'Ver,Y,M,D,h,m,s,Mag,Dur,Az1,Alt1,Az2,Alt2, Ra1, Dec1, Ra2, Dec2,ID,Long,Lat,Alt,Tz\\n'\n",
    "    csv_s += 'R91,' + start_time_str[0:4] + ',' + start_time_str[5:7] + ','\n",
    "    csv_s += start_time_str[8:10] + ',' + start_time_str[11:13] + ','\n",
    "    csv_s += start_time_str[14:16] + ',' + start_time_str[17:23] + ','\n",
    "    csv_s += '0.0,'+ str(sec) + ','\n",
    "    csv_s += str(az1_csv) + ',' + str(ev1) + ','\n",
    "    csv_s += str(az2_csv) + ',' + str(ev2) + ','\n",
    "    csv_s += str(ra1) + ',' + str(dec1) + ','\n",
    "    csv_s += str(ra2) + ',' + str(dec2) + ','\n",
    "    csv_s += ttt.meta['location'] + ','\n",
    "    csv_s += str(ttt.meta['obs_longitude']) + ','\n",
    "    csv_s += str(ttt.meta['obs_latitude']) + ','\n",
    "    csv_s += str(ttt.meta['obs_elevation']) + ','\n",
    "    csv_s += str(tz)\n",
    "        \n",
    "    \n",
    "    # now write the XML string\n",
    "    # there is no viable alternative to ugly hard-coding of the XML string  \n",
    "    # sample date: 2020-04-07T03:56:41.450\n",
    "    xml_s = '<?xml version=\"1.0\" encoding=\"UTF-8\" ?>'+'\\n'\n",
    "    xml_s += '<ufoanalyzer_record version =\"200\"'+'\\n\\t clip_name=\"'  \n",
    "    xml_s += ttt.meta['image_file'].rsplit('.',1)[0]   \n",
    "    xml_s += '\" o=\"1\" y=\"' + start_time_str[0:4]\n",
    "    xml_s += '\" mo=\"' + start_time_str[5:7]\n",
    "    xml_s += '\"\\n\\t d=\"' + start_time_str[8:10]\n",
    "    xml_s += '\" h=\"' + start_time_str[11:13]\n",
    "    xml_s += '\" m=\"' + start_time_str[14:16]\n",
    "    xml_s += '\" s=\"' + start_time_str[17:23]\n",
    "    xml_s += '\"\\n\\t tz=\"' + str(tz)\n",
    "    xml_s += '\" tme=\"1.000000\" lid=\"' + ttt.meta['location']\n",
    "    xml_s += '\" sid=\"' + ttt.meta['telescope'][0:2]\n",
    "    xml_s += '\"\\n\\t lng=\"' + str(ttt.meta['obs_longitude'])\n",
    "    xml_s += '\" lat=\"' + str(ttt.meta['obs_latitude'])\n",
    "    xml_s += '\" alt=\"' + str(ttt.meta['obs_elevation'])\n",
    "    xml_s += '\" cx=\"' + str(ttt.meta['cx'])\n",
    "    xml_s += '\"\\n\\t cy=\"' + str(ttt.meta['cy'])\n",
    "    xml_s += '\" fps=\"' + str(frame_rate)\n",
    "    xml_s += '\" interlaced=\"' + str(interlaced)\n",
    "    xml_s += '\" bbf=\"0\"\\n\\t frames=\"' + str(frames) \n",
    "    xml_s += '\" head=\"' + str(head)\n",
    "    xml_s += '\" tail=\"' + str(tail)\n",
    "    xml_s += '\" drop=\"-1\"\\n\\t dlev=\"0\" dsize=\"0\" sipos=\"0\" sisize=\"0\"\\n\\t trig=\"1'\n",
    "    xml_s += '\" observer=\"' + str(ttt.meta['observer'])\n",
    "    xml_s += '\" cam=\"' + str(ttt.meta['instrument'])\n",
    "    xml_s += '\" lens=\"' + str(ttt.meta['lens'])\n",
    "    xml_s += '\"\\n\\t cap=\"Not Applicable\" u2=\"224\" ua=\"243\" memo=\"'\n",
    "    xml_s += '\"\\n\\t az=\"' + str(ttt.meta['obs_az'])\n",
    "    xml_s += '\" ev=\"' + str(ttt.meta['obs_ev'])\n",
    "    xml_s += '\" rot=\"' + str(ttt.meta['obs_rot'])\n",
    "    xml_s += '\" vx=\"' + str(ttt.meta['fov_horiz'])\n",
    "    xml_s += '\"\\n\\t yx=\"0.000000\" dx=\"0.000000\" dy=\"0.000000\" k4=\"0.000000'\n",
    "    xml_s += '\"\\n\\t k3=\"-0.000000\" k2=\"0.000000\" atc=\"0.000000\" BVF=\"0.000000'\n",
    "    xml_s += '\"\\n\\t maxLev=\"255\" maxMag=\"0.000000\" minLev=\"0'\n",
    "    xml_s += '\" mimMag=\"0.0' # + str(ttt.meta['photometric_zero_point'])\n",
    "    xml_s += '\"\\n\\t dl=\"0\" leap=\"0\" pixs=\"0'\n",
    "    xml_s += '\" rstar=\"' + str(ttt.meta['astrometry_number_stars'])\n",
    "    xml_s += '\"\\n\\t ddega=\"0.000000\" ddegm=\"0.000000\" errm=\"0.00000\" Lmrgn=\"0'\n",
    "    xml_s += '\"\\n\\t Rmrgn=\"0\" Dmrgn=\"0\" Umrgn=\"0\">'\n",
    "    \n",
    "    xml_s += '\\n\\t<ua2_objects>'\n",
    "    xml_s += '\\n<ua2_object'\n",
    "    \n",
    "    xml_s += '\\n\\t fs=\"' + str(fs) \n",
    "    xml_s += '\" fe=\"' + str(fe) \n",
    "    xml_s += '\" fN=\"' + str(fN) \n",
    "    xml_s += '\" sN=\"' + str(sN) \n",
    "    xml_s += '\"\\n\\t sec=\"' + str(sec) \n",
    "    xml_s += '\" av=\"0.000000'       # investigate av \n",
    "    xml_s += '\" pix=\"0\" bmax=\"255'  # investigate pix\n",
    "    xml_s += '\"\\n\\t bN=\"0'          # investigate bN \n",
    "    xml_s += '\" Lmax=\"0.000000\" mag=\"0.000000\" cdeg=\"0.00000'\n",
    "    xml_s += '\"\\n\\t cdegmax=\"0.000000\" io=\"0\" raP=\"0.000000\" dcP=\"0.000000' \n",
    "    xml_s += '\"\\n\\t av1=\"0.000000\" x1=\"0.000000\" y1=\"0.000000\" x2=\"0.000000' \n",
    "    xml_s += '\"\\n\\t y2=\"0.000000\" az1=\"' + str(az1) \n",
    "    xml_s += '\" ev1=\"' + str(round(ev1,6)) \n",
    "    xml_s += '\" az2=\"' + str(round(az2,6)) \n",
    "    xml_s += '\"\\n\\t ev2=\"' + str(round(ev2,6)) \n",
    "    xml_s += '\" azm=\"999.9\" evm=\"999.9'\n",
    "    xml_s += '\" ra1=\"' + str(round(ra1,6)) \n",
    "    xml_s += '\"\\n\\t dc1=\"' + str(round(dec1,6)) \n",
    "    xml_s += '\" ra2=\"'+ str(round(ra2,6)) \n",
    "    xml_s += '\" dc2=\"' + str(round(dec2,6)) \n",
    "    xml_s += '\" ram=\"999.9' \n",
    "    xml_s += '\"\\n\\t dcm=\"999.9\" class=\"spo\" m=\"0\" dr=\"-1.000000' \n",
    "    xml_s += '\"\\n\\t dv=\"-1.000000\" Vo=\"-1.000000\" lng1=\"999.9\" lat1=\"999.9' \n",
    "    xml_s += '\"\\n\\t h1=\"100.000000\" dist1=\"0.000000\" gd1=\"0.000000\" azL1=\"-1.000000'  #in UFO, initial height is hard-coded at 100\n",
    "    xml_s += '\"\\n\\t evL1=\"-1.000000\" lng2=\"-999.000000\" lat2=\"-999.000000\" h2=\"-1.000000'\n",
    "    xml_s += '\"\\n\\t dist2=\"-1.000000\" gd2=\"-1.000000\" len=\"0.000000\" GV=\"0.000000'\n",
    "    xml_s += '\"\\n\\t rao=\"999.9\" dco=\"999.9\" Voo=\"0.000000\" rat=\"999.9'\n",
    "    xml_s += '\"\\n\\t dct=\"999.9\" memo=\"\">'\n",
    "    xml_s += '\\n\\t<ua2_objpath>'\n",
    "\n",
    "    for i in range(nlines):\n",
    "        fno = fs + int(round(cumu_times[i]/frame_step,0))\n",
    "        xml_s += '\\n<ua2_fdata2 fno=\"'\n",
    "        if fno < 100:\n",
    "            xml_s += ' '\n",
    "        xml_s += str(fno) \n",
    "        xml_s += '\" b=\"000\" bm=\"000\" Lsum=\"   000.0'\n",
    "        if ttt.meta['mag_label'] == 'mag':\n",
    "            xml_s += '\" mag=\"' + str(round(ttt['mag'][i],6))\n",
    "        else:    \n",
    "            xml_s += '\" mag=\"0.000000'\n",
    "        xml_s += '\" az=\"' + str(round(ttt['azimuth'][i],6))\n",
    "        xml_s += '\" ev=\"' + str(round(ttt['altitude'][i],6))\n",
    "        xml_s += '\" ra=\"' + str(round(ttt['ra'][i],6))\n",
    "        xml_s += '\" dec=\"' + str(round(ttt['dec'][i],6))\n",
    "        xml_s += '\"></ua2_fdata2>'\n",
    "\n",
    "    xml_s += '\\n\\t</ua2_objpath>'\n",
    "    xml_s += '\\n</ua2_object>'\n",
    "    xml_s += '\\n\\t</ua2_objects>'\n",
    "    xml_s += '\\n</ufoanalyzer_record>\\n'\n",
    "\n",
    "    return xml_s, csv_s ;   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desert Fireball Network functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfn_to_std(ttt):\n",
    "    # converts a table in DFN/UKFN format to Standard format\n",
    "    \n",
    "    meta_dic = {'obs_latitude': ttt.meta['obs_latitude'],\n",
    "       'obs_longitude': ttt.meta['obs_longitude'],\n",
    "       'obs_elevation': ttt.meta['obs_elevation'],\n",
    "       'origin': ttt.meta['origin'],\n",
    "       'location': ttt.meta['location'],\n",
    "       'telescope': ttt.meta['telescope'],\n",
    "       'camera_id': ttt.meta['dfn_camera_codename'],\n",
    "       'observer': ttt.meta['observer'],\n",
    "       'comment': '',\n",
    "       'instrument': ttt.meta['instrument'],\n",
    "       'lens': ttt.meta['lens'],\n",
    "       'cx' : ttt.meta['NAXIS1'],     \n",
    "       'cy' : ttt.meta['NAXIS2'],     \n",
    "       'photometric_band' : 'Unknown',     \n",
    "       'image_file' : ttt.meta['image_file'],\n",
    "       'isodate_start_obs': ttt.meta['isodate_start_obs'],   \n",
    "       'isodate_calib': ttt.meta['isodate_mid_obs'],   \n",
    "       'exposure_time': ttt.meta['exposure_time'],   \n",
    "       'astrometry_number_stars' : ttt.meta['astrometry_number_stars'],\n",
    "       # 'photometric_zero_point': ttt.meta['photometric_zero_point'),    \n",
    "       # 'photometric_zero_point_uncertainty': ttt.meta['photometric_zero_point_uncertainty'),\n",
    "       'mag_label': 'no_mag_data',     \n",
    "       'no_frags': 1,\n",
    "       'obs_az': 0.0,     \n",
    "       'obs_ev': 90.0,     \n",
    "       'obs_rot': 0.0,     \n",
    "       'fov_horiz': 180.0,     \n",
    "       'fov_vert': 180.0,     \n",
    "       }\n",
    "\n",
    "    # initialise table\n",
    "    ttt_new = Table()        \n",
    "    #Update the table metadata\n",
    "    ttt_new.meta.update(meta_dic)   \n",
    "   \n",
    "    # RA and DEC calculation\n",
    "    ra_calc_array  = []\n",
    "    dec_calc_array = []\n",
    "    obs_latitude = ttt.meta['obs_latitude']\n",
    "    obs_longitude = ttt.meta['obs_longitude']\n",
    "    # start of J2000 epoch\n",
    "    ts = datetime.strptime(\"2000-01-01T12:00:00.000\",ISO_FORMAT)\n",
    "    start_epoch = datetime2JD(ts)\n",
    "    no_lines = len(ttt['azimuth'])\n",
    "\n",
    "    for i in range(no_lines):\n",
    "        az   = float(ttt['azimuth'][i])\n",
    "        elev = float(ttt['altitude'][i])\n",
    "        \n",
    "        time_stamp = str(ttt['datetime'][i])  \n",
    "        ts = datetime.strptime(time_stamp,ISO_FORMAT)\n",
    "        JD = datetime2JD(ts)\n",
    "        \n",
    "        # USE Az and Alt to calculate correct RA and DEC in epoch of date, then precess back to J2000\n",
    "        temp_ra, temp_dec = altAz2RADec(az, elev, JD, obs_latitude, obs_longitude)\n",
    "        temp_ra, temp_dec = equatorialCoordPrecession(JD, start_epoch, temp_ra, temp_dec) \n",
    "        ra_calc_array.append(temp_ra )\n",
    "        dec_calc_array.append(temp_dec )        \n",
    "        \n",
    "    \n",
    "    # create columns\n",
    "    ttt_new['datetime'] = ttt['datetime']\n",
    "    ttt_new['ra']  = ra_calc_array  * u.degree\n",
    "    ttt_new['dec'] = dec_calc_array * u.degree \n",
    "    ttt_new['azimuth'] = ttt['azimuth']\n",
    "    ttt_new['altitude'] = ttt['altitude']\n",
    "    ttt_new['no_mag_data'] = 0.0\n",
    "    ttt_new['x_image'] = ttt['x_image']\n",
    "    ttt_new['y_image'] = ttt['y_image']\n",
    "    \n",
    "    return([ttt_new], 1);\n",
    "\n",
    "\n",
    "\n",
    "def std_to_dfn(ttt):\n",
    "    #converts a table in standard format to DFN/UKFN format\n",
    "    cx_true = 0\n",
    "    cy_true = 0\n",
    "    calib_true = 0\n",
    "    mag_true = 0\n",
    "    frags_true = 0\n",
    "    comment_true = 0\n",
    "    phot_true = 0\n",
    "    \n",
    "    for key_name in ttt.meta.keys(): \n",
    "        if 'cx' in key_name:\n",
    "            cx_true = 1\n",
    "        if 'cy' in key_name:\n",
    "            cy_true = 1\n",
    "        if 'isodate_calib' in key_name:\n",
    "            calib_true = 1\n",
    "        if 'mag_label' in key_name:\n",
    "            mag_true = 1\n",
    "        if 'no_frag' in key_name:\n",
    "            frags_true = 1\n",
    "        if 'comment' in key_name:\n",
    "            comment_true = 1\n",
    "        if 'photometric_band' in key_name:\n",
    "            phot_true = 1\n",
    "            \n",
    "\n",
    "    if cx_true > .5 :\n",
    "        ttt.meta['NAXIS1'] = ttt.meta.pop('cx')    \n",
    "    if cy_true > .5 :\n",
    "        ttt.meta['NAXIS2'] = ttt.meta.pop('cy')    \n",
    "    if calib_true > .5 :\n",
    "        ttt.meta['isodate_mid_obs'] = ttt.meta.pop('isodate_calib')    \n",
    "    if mag_true > .5 :\n",
    "        ttt.remove_columns(ttt.meta['mag_label'])\n",
    "        ttt.meta.pop('mag_label')\n",
    "    if frags_true > .5 :\n",
    "        ttt.meta.pop('no_frags')\n",
    "    if comment_true > .5 :\n",
    "        ttt.meta.pop('comment')\n",
    "    if phot_true > .5 :\n",
    "        ttt.meta.pop('photometric_band')\n",
    "\n",
    "    ttt.meta.pop('obs_az')\n",
    "    ttt.meta.pop('obs_ev')\n",
    "    ttt.meta.pop('obs_rot')\n",
    "    ttt.meta.pop('fov_horiz')\n",
    "    ttt.meta.pop('fov_vert')\n",
    "       \n",
    "\n",
    "    # fireball ID\n",
    "    # leave the default if you don't know\n",
    "    ttt.meta['event_codename'] = 'DN200000_00'\n",
    "\n",
    "    ## Uncertainties - if you have no idea of what they are, leave the default values\n",
    "    # time uncertainty array\n",
    "    ttt['time_err_plus'] = 0.1 *u.second\n",
    "    ttt['time_err_minus'] = 0.1 *u.second\n",
    "    # astrometry uncertainty array\n",
    "    ttt['err_plus_azimuth'] = 1/60. *u.degree\n",
    "    ttt['err_minus_azimuth'] = 1/60. *u.degree\n",
    "    ttt['err_plus_altitude'] = 1/60. *u.degree\n",
    "    ttt['err_minus_altitude'] = 1/60. *u.degree\n",
    "\n",
    "    #delete surplus columns\n",
    "    ttt.remove_columns(['ra','dec'])\n",
    "    return(ttt);    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FRIPON/SCAMP functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fripon_stations():\n",
    "    # get a table of FRIPON camera locations\n",
    "    # data = Stations,Latitude,Longitude,Altitude,Country,City,Camera,Switch,Status\n",
    "\n",
    "    stations_file_name = 'https://raw.githubusercontent.com/SCAMP99/scamp/master/FRIPON_location_list.csv'    \n",
    "\n",
    "    import requests\n",
    "    try:\n",
    "        r = requests.get(stations_file_name)\n",
    "        loc_table = ascii.read(r.text, delimiter=',')\n",
    "    except:\n",
    "        # create columns for the UK stations only. \n",
    "        loc_table = Table()\n",
    "        loc_table['Stations'] = 'ENGL01','ENNI01','ENNW01','ENSE01','ENSE02','ENSW01','GBWL01','ENNW02'\n",
    "        loc_table['Latitude'] = '50.75718','54.35235','53.474365','51.5761','51.2735','50.80177','51.48611','53.6390851'\n",
    "        loc_table['Longitude'] = '0.26582','-6.649632','-2.233606','-1.30761','1.07208','-3.18441','-3.17787','-2.1322892'\n",
    "        loc_table['Altitude'] = '61','75','70','200','21','114','33','177'\n",
    "        loc_table['Country'] = 'England','England','England','England','England','England','GreatBritain','England'\n",
    "        loc_table['City'] = 'Eastbourne','Armagh','Manchester','Harwell','Canterbury','Honiton','Cardiff','Rochester'\n",
    "        loc_table['Camera'] = 'BASLER 1300gm','BASLER 1300gm','BASLER 1300gm','BASLER 1300gm','BASLER 1300gm','DMK 23G445','BASLER 1300gm','BASLER 1300gm'\n",
    "        loc_table['Switch'] = 'TL-SG2210P','TL-SG2210P','T1500G-10PS','TL-SG2210P','TL-SG2210P','TL-SG2210P','TL-SG2210P','TL-SG2210P'\n",
    "        loc_table['Status'] = 'Production','Production','Production','NotOperational','Production','Production','Production','Production'\n",
    "       \n",
    "    no_stations = len(loc_table['Latitude'])\n",
    "\n",
    "    #The first key may have extra characters in it - if so, rename it.\n",
    "    for key_name in loc_table.keys(): \n",
    "        if 'Stations' in key_name:\n",
    "            if not key_name == 'Stations':\n",
    "                loc_table.rename_column(key_name,'Stations')\n",
    "    \n",
    "    return(loc_table, no_stations);\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def fripon_to_std(fname,ttt_old, loc_table, no_stations):\n",
    "    # convert data from FRIPON/SCAMP format into standard format\n",
    "    \n",
    "    #check that the .met file contains data    \n",
    "    if len(ttt_old['TIME']) < 1:    \n",
    "        print('no data in file') \n",
    "        return([], 0);\n",
    "    \n",
    "    #process the filename for data, e.g. 'C:/Users/jr63/Google Drive/0-Python/20200324T023233_UT_FRNP03_SJ.met'\n",
    "    print(fname)\n",
    "    n1 = fname.rfind('/')\n",
    "    n2 = fname.rfind('\\\\')\n",
    "    n = max(n1, n2)\n",
    "    \n",
    "    station_str = fname[n+20:n+26]\n",
    "    analyst_str = fname[n+27:n+29]\n",
    "                \n",
    "    print('No. Rows of station data = ',no_stations,' sought station = ',station_str,'\\n')\n",
    "\n",
    "    i = -1\n",
    "    for j in range(no_stations):\n",
    "        if loc_table['Stations'][j] == station_str:\n",
    "            i = j\n",
    "            break\n",
    "    \n",
    "    if i < 0:    \n",
    "        print('FRIPON Station name \"' + station_str + '\" not found.') \n",
    "        return([], 0);\n",
    "\n",
    "    \n",
    "    # Now get on with construction of the metadata dictionary\n",
    "        \n",
    "    # camera resolution\n",
    "    if loc_table['Camera'][i] == 'BASLER 1300gm':\n",
    "        cx = 1296\n",
    "        cy = 966\n",
    "    elif loc_table['Camera'][i] == 'DMK 23G445':\n",
    "        cx = 1280\n",
    "        cy = 960\n",
    "    elif loc_table['Camera'][i] == 'DMK 33GX273':\n",
    "        cx = 1440\n",
    "        cy = 1080\n",
    "    else :    \n",
    "        cx = 0\n",
    "        cy = 0\n",
    "\n",
    "    #convert time to ISO format\n",
    "    iso_date_str = ttt_old['TIME'][0]   # ttt_old['TIME'][0] is a 'numpy.str_' object \n",
    "\n",
    "    # set up a new table\n",
    "    ttt = Table()\n",
    "    ttt['datetime'] = Time(ttt_old['TIME']).isot # ttt['datetime'][0] is a 'numpy.str_' object\n",
    "    event_time = str(ttt['datetime'][0])\n",
    "\n",
    "    # now find time-related metadata\n",
    "    no_lines = len(ttt['datetime'])\n",
    "    if no_lines >= 1:\n",
    "        start_day = Time(ttt['datetime'][0])\n",
    "        end_day = Time(ttt['datetime'][no_lines-1])\n",
    "        half_time = end_day - start_day\n",
    "        half_str = str(half_time)\n",
    "        half_sec = round(float(half_str)*24*60*60/2,6)\n",
    "        isodate_calib = start_day + timedelta(seconds=half_sec)\n",
    "        isodate_calib_str = str(isodate_calib)\n",
    "    else:    \n",
    "        isodate_calib_str = event_time\n",
    "          \n",
    "    obs_latitude = float(loc_table['Latitude'][i])\n",
    "    obs_longitude = float(loc_table['Longitude'][i])\n",
    "    obs_elevation = float(loc_table['Altitude'][i])\n",
    "    obs_location = str(loc_table['City'][i])\n",
    "    \n",
    "    \n",
    "    # For old data from stations that have been moved, make changes here to reflect the historic location\n",
    "    if (station_str == 'ENGL01'):\n",
    "        obs_year = int(ttt['datetime'][0][0:4])\n",
    "        print('Year = ', obs_year)\n",
    "        if(obs_year < 2021):\n",
    "            obs_latitude = 51.637359\n",
    "            obs_longitude = -0.169234\n",
    "            obs_elevation = 87.0\n",
    "            obs_location = 'East Barnet'\n",
    "    \n",
    "      \n",
    "    # Update the metadata. \n",
    "    meta_dic = {'obs_latitude': obs_latitude,\n",
    "    'obs_longitude': obs_longitude,\n",
    "    'obs_elevation': obs_elevation,\n",
    "    'origin': 'FRIPON',\n",
    "    'location': obs_location,\n",
    "    'telescope': station_str,\n",
    "    'camera_id': station_str,\n",
    "    'observer': analyst_str,\n",
    "    'comment': '',            \n",
    "    'instrument': str(loc_table['Camera'][i]),\n",
    "    'lens': 'unknown',\n",
    "    'cx': cx,            \n",
    "    'cy': cy,\n",
    "    'photometric_band' : 'Unknown',     \n",
    "    'image_file' : 'unknown',\n",
    "    'isodate_start_obs': event_time,\n",
    "    'isodate_calib': isodate_calib_str, \n",
    "    'exposure_time': 2.0 * half_sec,\n",
    "    'astrometry_number_stars': 0,\n",
    "    # 'photometric_zero_point': 0.0,\n",
    "    # 'photometric_zero_point_uncertainty': 0.0,\n",
    "    'mag_label': 'FLUX_AUTO',            \n",
    "    'no_frags': 1,\n",
    "    'obs_az': 0.0,     \n",
    "    'obs_ev': 90.0,     \n",
    "    'obs_rot': 0.0,     \n",
    "    'fov_horiz': 180.0,     \n",
    "    'fov_vert': 180.0,     \n",
    "    }\n",
    "                   \n",
    "    ttt.meta.update(meta_dic)    \n",
    "\n",
    "    # calculate az and alt\n",
    "    az_calc_array  = []\n",
    "    alt_calc_array  = []\n",
    "\n",
    "    # start of J2000 epoch\n",
    "    ts = datetime.strptime(\"2000-01-01T12:00:00.000\",\"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    start_epoch = datetime2JD(ts)\n",
    "\n",
    "    for k in range (no_lines) :\n",
    "        ra   = float(ttt_old['ALPHAWIN_J2000'][k])\n",
    "        dec   = float(ttt_old['DELTAWIN_J2000'][k])\n",
    "        ts = datetime.strptime(str(ttt['datetime'][k]),\"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "        JD = datetime2JD(ts)\n",
    "\n",
    "        # RA and DEC are in J2000 epoch.  Precess to epoch of date, then convert to Az and Alt using RMS code\n",
    "        temp_ra, temp_dec = equatorialCoordPrecession(start_epoch, JD, ra, dec)  \n",
    "        temp_azim, temp_elev = raDec2AltAz(temp_ra, temp_dec, JD, obs_latitude, obs_longitude)\n",
    "        az_calc_array.append(temp_azim)\n",
    "        alt_calc_array.append(temp_elev)\n",
    "\n",
    "    #ttt['datetime'] already done above    \n",
    "    ttt['ra'] = ttt_old['ALPHAWIN_J2000'] * u.degree\n",
    "    ttt['dec'] = ttt_old['DELTAWIN_J2000'] * u.degree\n",
    "    ttt['azimuth'] = az_calc_array * u.degree\n",
    "    ttt['altitude'] = alt_calc_array * u.degree\n",
    "    ttt['FLUX_AUTO'] = ttt_old['FLUX_AUTO']\n",
    "    ttt['x_image'] = ttt_old['XWIN_IMAGE']\n",
    "    ttt['y_image'] = ttt_old['YWIN_IMAGE']\n",
    "  \n",
    "    return([ttt], 1);\n",
    " \n",
    "\n",
    "def std_to_fripon(ttt):\n",
    "    #converts standard format to FRIPON\n",
    "    \n",
    "    no_lines = len(ttt['datetime'])\n",
    "    \n",
    "    ttt_new = Table()\n",
    "    ttt_new['NUMBER'] = np.linspace(1, no_lines, no_lines)\n",
    "    ttt_new['FLUX_AUTO'] = 0  \n",
    "    ttt_new['FLUXERR_AUTO'] = 0   \n",
    "    ttt_new['XWIN_IMAGE'] = ttt['x_image']       \n",
    "    ttt_new['YWIN_IMAGE'] = ttt['y_image']   \n",
    "    ttt_new['ALPHAWIN_J2000'] = ttt['ra']    \n",
    "    ttt_new['DELTAWIN_J2000'] = ttt['dec']    \n",
    "    ttt_new['TIME'] = ttt['datetime']\n",
    "    \n",
    "    ttt_new.meta.update(ttt.meta)   \n",
    "    return(ttt_new);\n",
    "\n",
    "\n",
    "def fripon_write(ttt):\n",
    "    # writes a table in FRIPON format to two strings, which it returns\n",
    "    # needed to hard-code this as SExtractor is supported in Astropy only for table read, not table write.\n",
    "\n",
    "    fri_str  =   '#   1 NUMBER                 Running object number                          '\n",
    "    fri_str += '\\n#   2 FLUX_AUTO              Flux within a Kron-like elliptical aperture                [count]'    \n",
    "    fri_str += '\\n#   3 FLUXERR_AUTO           RMS error for AUTO flux                                    [count]'\n",
    "    fri_str += '\\n#   4 XWIN_IMAGE             Windowed position estimate along x                         [pixel]'\n",
    "    fri_str += '\\n#   5 YWIN_IMAGE             Windowed position estimate along y                         [pixel]'\n",
    "    fri_str += '\\n#   6 ALPHAWIN_J2000         Windowed right ascension (J2000)                           [deg]'\n",
    "    fri_str += '\\n#   7 DELTAWIN_J2000         windowed declination (J2000)                               [deg]'\n",
    "    fri_str += '\\n#   8 TIME                   Time of the frame                                          [fits]'\n",
    "    \n",
    "    no_rows = len(ttt['TIME'])\n",
    "    for j in range(no_rows): \n",
    "        fri_str += '\\n'+ str(j+1)\n",
    "        fri_str += ' ' + str(round(ttt['FLUX_AUTO'][j],6)) \n",
    "        fri_str += ' ' + str(round(ttt['FLUXERR_AUTO'][j],6))\n",
    "        fri_str += ' ' + str(round(ttt['XWIN_IMAGE'][j],6))\n",
    "        fri_str += ' ' + str(round(ttt['YWIN_IMAGE'][j],6))\n",
    "        fri_str += ' ' + str(round(ttt['ALPHAWIN_J2000'][j],6))\n",
    "        fri_str += ' ' + str(round(ttt['DELTAWIN_J2000'][j],6)) \n",
    "        fri_str += ' ' + str(ttt['TIME'][j])    \n",
    "    \n",
    "    #write the location as a txt file    \n",
    "    loc_str = 'latitude = ' + str(ttt.meta['obs_latitude'])\n",
    "    loc_str += '\\nlongitude = ' + str(ttt.meta['obs_longitude'])\n",
    "    loc_str += '\\nelevation = ' + str(ttt.meta['obs_elevation'])\n",
    "                                               \n",
    "    return(fri_str, loc_str);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel CSV functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_to_csv(ttt):\n",
    "    \n",
    "    \n",
    "    #write the metadata to csv_str\n",
    "    csv_str =  'Converted Meteor Data\\n'\n",
    "    csv_str += '\\nObservatory latitude (deg),' + str(ttt.meta['obs_latitude'])\n",
    "    csv_str += '\\nObservatory longitude (deg),' + str(ttt.meta['obs_longitude'])\n",
    "    csv_str += '\\nObservatory elevation (metres ASL),' + str(ttt.meta['obs_elevation'])\n",
    "    csv_str += '\\nNetwork name,' + str(ttt.meta['origin'])\n",
    "    csv_str += '\\nLocation,' + str(ttt.meta['location'])\n",
    "    csv_str += '\\nName of station,' + str(ttt.meta['telescope'])\n",
    "    csv_str += '\\nCamera id,' + str(ttt.meta['camera_id'])\n",
    "    csv_str += '\\nObserver,' + str(ttt.meta['observer'])\n",
    "    csv_str += '\\nComment,' + str(ttt.meta['comment'])\n",
    "    csv_str += '\\nCamera model,' + str(ttt.meta['instrument'])\n",
    "    csv_str += '\\nLens make and model,' + str(ttt.meta['lens'])\n",
    "    csv_str += '\\nHorizontal pixel count,' + str(ttt.meta['cx'])\n",
    "    csv_str += '\\nVertical pixel count,' + str(ttt.meta['cy']) \n",
    "    csv_str += '\\nPhotometric band,' + str(ttt.meta['photometric_band']) \n",
    "    csv_str += '\\nName of image file,' + str(ttt.meta['image_file'])\n",
    "    csv_str += '\\nStart datetime of clip,' + str(ttt.meta['isodate_start_obs'])\n",
    "    csv_str += '\\nDatetime of astrometry,' + str(ttt.meta['isodate_calib'])\n",
    "    csv_str += '\\nTotal length of clip (sec),' + str(ttt.meta['exposure_time'])\n",
    "    csv_str += '\\nNumber of stars identified in astrometry,' + str(ttt.meta['astrometry_number_stars'])\n",
    "    # csv_str += '\\nPhotometric zero point,' + str(ttt.meta['photometric_zero_point'])\n",
    "    # csv_str += '\\nPhotometric zero point uncertainty,' + str(ttt.meta['photometric_zero_point_uncertainty'])\n",
    "    csv_str += '\\nMagnitude measure,' + str(ttt.meta['mag_label'])\n",
    "    csv_str += '\\nNumber of fragments,' + str(ttt.meta['no_frags'])\n",
    "    csv_str += '\\nAzimuth of camera centrepoint (deg),' + str(ttt.meta['obs_az']) \n",
    "    csv_str += '\\nElevation of camera centrepoint (deg),' + str(ttt.meta['obs_ev'])\n",
    "    csv_str += '\\nRotation of camera from horizontal (deg),' + str(ttt.meta['obs_rot']) \n",
    "    csv_str += '\\nHorizontal FOV (deg),' + str(ttt.meta['fov_horiz']) \n",
    "    csv_str += '\\nVertical FOV (deg),' + str(ttt.meta['fov_vert']) \n",
    "\n",
    "    # For each row, add the excel date.  \n",
    "    # the Excel date 36526.5 is equivalent to 01/01/2000 12pm - don't use because of 5 leap seconds before 1/1/2017\n",
    "    # the Excel date 42736.5 is equivalent to 01/01/2017 12pm\n",
    "    ts = datetime.strptime(\"2017-01-01T12:00:00.000\",ISO_FORMAT)\n",
    "    epoch_day = Time(ts)\n",
    "    \n",
    "    csv_str += '\\n\\nDate/Time,Row No.,RA,Dec,Az,Alt,Magnitude,X_image,Y_image,Year,Month,Day,Hour,Min,Sec'\n",
    "    for j in range (len(ttt['datetime'])): \n",
    "        ts = datetime.strptime(ttt['datetime'][j],ISO_FORMAT)\n",
    "        obs_day = Time(ts)\n",
    "        excel_day = float(str(obs_day - epoch_day))+ 42736.5 \n",
    "        csv_str += '\\n' + str(excel_day)    \n",
    "        csv_str += ','+ str(j+1)\n",
    "        csv_str += ',' + str(round(ttt['ra'][j],6))\n",
    "        csv_str += ',' + str(round(ttt['dec'][j],6))\n",
    "        csv_str += ',' + str(round(ttt['azimuth'][j],6))\n",
    "        csv_str += ',' + str(round(ttt['altitude'][j],6))\n",
    "        csv_str += ',' + str(round(ttt[str(ttt.meta['mag_label'])][j],6))\n",
    "        csv_str += ',' + str(round(ttt['x_image'][j],6))\n",
    "        csv_str += ',' + str(round(ttt['y_image'][j],6))\n",
    "        date_str = ttt['datetime'][j].replace('-',',')\n",
    "        date_str = date_str.replace('T',',')\n",
    "        date_str = date_str.replace(':',',')\n",
    "        date_str = date_str.replace(' ',',')\n",
    "        csv_str += ',' + date_str\n",
    "    \n",
    "    return csv_str ;\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMS functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_camera_json(_file_path):\n",
    "    #extract json data\n",
    "    _json_str = open(_file_path).read()\n",
    "    cam_data = json.loads(_json_str)\n",
    "        \n",
    "    cam_dict = {}\n",
    "    \n",
    "    for file_name in cam_data:\n",
    "        #sib-dict with info about camera\n",
    "        cam_snap = cam_data[file_name]\n",
    "        \n",
    "        #get info from file name\n",
    "        file_name_info = regex.search('(.*)_(\\d{8}_\\d{6}_\\d{3})', file_name)\n",
    "        \n",
    "        #camera name in string\n",
    "        file_prefix = file_name_info[1]\n",
    "\n",
    "        #camera timestamp in string\n",
    "        file_timestamp_string = file_name_info[2] + \"000\"\n",
    "        file_timestamp_old = datetime.strptime(file_timestamp_string, \"%Y%m%d_%H%M%S_%f\")\n",
    "        file_timestamp_string = file_timestamp_old.strftime(ISO_FORMAT)\n",
    "        file_timestamp = Time(datetime.strptime(file_timestamp_string,ISO_FORMAT)).isot\n",
    "        #print('1.file_timestamp_string = ',file_timestamp_string, ' file_timestamp = ',file_timestamp)\n",
    "        \n",
    "        cam_snap.update({\n",
    "            \"timestamp\": file_timestamp,\n",
    "            \"file_name\": file_name\n",
    "        })\n",
    "        \n",
    "        # have a list of calibrations for each camera (based on file prefix like FF_IE0001)\n",
    "        cam_name_info_list = []\n",
    "        if file_prefix in cam_dict:\n",
    "            file_prefix_info_list = cam_dict[file_prefix]\n",
    "        \n",
    "        #add camera snap to the cam_dict list\n",
    "        cam_name_info_list.append(cam_snap)\n",
    "        cam_dict.update({file_prefix: cam_name_info_list})\n",
    "            \n",
    "    # print(\"Got camera data \")\n",
    "    \n",
    "    return cam_dict\n",
    "\n",
    "def find_most_recent_cam_calibration(cam_list, timestamp):\n",
    "    previous_cam_info = cam_list[0]\n",
    "    \n",
    "    # we assume ascending order\n",
    "    for current_cam_info in cam_list: \n",
    "        if not current_cam_info['timestamp']:\n",
    "            continue;\n",
    "        \n",
    "        timestamp_meteor  =  datetime.strptime(timestamp,                    ISO_FORMAT)\n",
    "        timestamp_current =  datetime.strptime(current_cam_info['timestamp'],ISO_FORMAT)\n",
    "        deltaT = (timestamp_meteor - timestamp_current ).total_seconds()\n",
    "        \n",
    "        if deltaT >= 0:\n",
    "            previous_cam_info = current_cam_info\n",
    "        else:\n",
    "            return previous_cam_info\n",
    "    \n",
    "    return previous_cam_info\n",
    "\n",
    "def rms_to_dict(RMSMeteorText):\n",
    "    # convert to list of rows\n",
    "    rows_list = RMSMeteorText.split('\\n')\n",
    "    \n",
    "    # Example of how data is:\n",
    "    # -------------------------------------------------------\n",
    "    # FF_IE0001_20200126_225518_555_0475904.fits\n",
    "    # Recalibrated with RMS on: 2020-02-03 16:40:39.821536 UTC\n",
    "    # IE0001   0001    0016      0025.00  000.0    000.0    00.0     004.1   0052.8 0015.5\n",
    "    # 181.5530 0705.12 0398.18   020.7986 +22.6715 278.2975 +22.4058 000672  3.28\n",
    "    # ... (0016 total) ...\n",
    "    # 196.6360 0722.07 0457.92   017.3488 +20.2848 279.3342 +18.5235 000320  4.08\n",
    "    # -------------------------------------------------------\n",
    "    \n",
    "    #in_block# The File is read as:\n",
    "    #        # -------------------------------------------------------\n",
    "    #   -3   # file_name\n",
    "    #   -2   # calibration\n",
    "    #   -1   # Cam#     Meteor# #Segments fps      hnr      mle      bin      Pix/fm  Rho    Phi\n",
    "    #   +n   # Frame#   Col     Row       RA       Dec      Azim     Elev     Inten   Mag\n",
    "    #   ...  # ... (#Segments) ...\n",
    "    #    0   # Frame#   Col     Row       RA       Dec      Azim     Elev     Inten   Mag\n",
    "    #        # -------------------------------------------------------\n",
    "    \n",
    "    #\n",
    "    # We convert this to:\n",
    "    # [{\n",
    "    # cam, meteor, segments, fps, hnr, mle, bin, pix/fm, rho, phi, \n",
    "    # file_name, file_prefix, timestamp, duration, min_magnitude, max_intensity, calibration\n",
    "    # frames: [{\n",
    "    #     frame, timestamp, col, row, ra, dec, azim, elev, inten, mag\n",
    "    #   },{\n",
    "    #     ... \n",
    "    #   }]\n",
    "    # },{\n",
    "    #   ...\n",
    "    # }]\n",
    "    #\n",
    "    \n",
    "    shot_info_labels  = [\"cam\", \"meteor\", \"segments\", \"fps\", \"hnr\", \"mle\", \"bin\", \"pix/fm\", \"rho\", \"phi\"]\n",
    "    frame_info_labels = [\"frame\", \"col\", \"row\", \"ra\", \"dec\", \"azim\", \"elev\", \"inten\", \"mag\"]\n",
    "\n",
    "    # meta sections split by 53-long lines of \"---------------\"\n",
    "    # data sections split by 55-long lines of \"---------------\"\n",
    "    line = '-{55}'\n",
    "    \n",
    "    #loop variables\n",
    "    in_block = 0\n",
    "    data = []\n",
    "    prev_event = False\n",
    "    current_event = {}\n",
    "    \n",
    "    for row in rows_list:\n",
    "        #test for a new data row for a meteor event\n",
    "        if (regex.match(line, row)):\n",
    "            in_block = -3\n",
    "            current_event={}\n",
    "            continue\n",
    "        \n",
    "        #get file info\n",
    "        if (in_block == -3):\n",
    "            in_block =  -2\n",
    "            file_name = row.strip()\n",
    "            \n",
    "            file_name_info = regex.search('(.*)_(\\d{8}_\\d{6}_\\d{3})', file_name)\n",
    "            # print(' file_name_info = ', file_name_info)\n",
    "            #camera name in string\n",
    "            file_prefix = file_name_info[1]\n",
    "            \n",
    "            #camera timestamp in string\n",
    "            file_timestamp_string = file_name_info[2] + \"000\"\n",
    "            file_timestamp_old = datetime.strptime(file_timestamp_string, \"%Y%m%d_%H%M%S_%f\")\n",
    "            file_timestamp_string = file_timestamp_old.strftime(ISO_FORMAT)\n",
    "            file_timestamp = Time(datetime.strptime(file_timestamp_string,ISO_FORMAT)).isot\n",
    "            # print('2.file_timestamp_string = ',file_timestamp_string, ' file_timestamp = ',file_timestamp)\n",
    "            \n",
    "            current_event.update({\n",
    "                'file_name': row.strip(),\n",
    "                'file_prefix': file_prefix,\n",
    "                'timestamp': file_timestamp \n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        #get calibration info\n",
    "        if (in_block == -2):\n",
    "            in_block =  -1\n",
    "            current_event.update( {'calibration': row.strip()} )\n",
    "            continue\n",
    "            \n",
    "        #get info about camera and the shot\n",
    "        if (in_block == -1):\n",
    "            info = regex.split('[\\s\\t]+', row.strip())\n",
    "            \n",
    "            #turn into dict using labels\n",
    "            for i in range(len(info)):\n",
    "                current_event.update({shot_info_labels[i]: info[i]})\n",
    "            \n",
    "            current_event.update({'frames': []})\n",
    "            #number of frames\n",
    "            in_block = int(current_event['segments'])\n",
    "            continue\n",
    "    \n",
    "    \n",
    "        #get info from each individual frame\n",
    "        if (in_block > 0):\n",
    "            in_block -= 1\n",
    "            info = regex.split('[\\s\\t]+', row.strip())\n",
    "            \n",
    "            current_frame = {}\n",
    "            frames_list = current_event['frames']\n",
    "            \n",
    "            #turn into dict using labels\n",
    "            for i in range(len(info)):\n",
    "                current_frame.update({frame_info_labels[i]: info[i]})\n",
    "            \n",
    "            #get frame timestamp\n",
    "            frame_time = float(current_frame['frame']) / float(current_event['fps'])\n",
    "            dt = timedelta(seconds = frame_time)\n",
    "            \n",
    "            timestamp_XYZ = datetime.strptime(current_event['timestamp'], ISO_FORMAT)\n",
    "            frame_timestamp = timestamp_XYZ + dt\n",
    "            \n",
    "            \n",
    "            #add to frame info\n",
    "            current_frame.update({'timestamp': frame_timestamp})\n",
    "            \n",
    "            frames_list.append(current_frame)\n",
    "            current_event.update({'frames': frames_list})\n",
    "            \n",
    "            # calculate some final information before adding it to the list\n",
    "            if (in_block == 0):\n",
    "                \n",
    "                # calculate: duration, min_magnitude, max_intensity, col_speed, row_speed\n",
    "                current_event = rms_update_dict_info(current_event)\n",
    "                \n",
    "                # check if the event is a continuation of the previous event \n",
    "                if (prev_event):\n",
    "                    is_same_event = rms_check_if_same_event(prev_event, current_event)\n",
    "                else:\n",
    "                    is_same_event = False\n",
    "                        \n",
    "                # if so, expand on the previous event data\n",
    "                if is_same_event:\n",
    "                    # append current event info\n",
    "                    prev_event['frames'].extend(current_event['frames'])\n",
    "                    # calculate again: duration, min_magnitude, max_intensity, col_speed, row_speed\n",
    "                    prev_event = rms_update_dict_info(prev_event)\n",
    "                \n",
    "                else:\n",
    "                    # add previous event and save current event as previous\n",
    "                    data.append(prev_event)\n",
    "                    prev_event = current_event\n",
    "                    \n",
    "                in_block = False\n",
    "        #\n",
    "    #####\n",
    "    # end of for loop\n",
    "    # add final prev_event\n",
    "    data.append(prev_event)    \n",
    "        \n",
    "    return data\n",
    "\n",
    "# update some stats using data from the 'frames' list\n",
    "def rms_update_dict_info(dict_event):\n",
    "\n",
    "    #get the duration of the event\n",
    "    start_time  = dict_event['frames'][ 0]['timestamp']\n",
    "    end_time    = dict_event['frames'][-1]['timestamp']\n",
    "    duration    = (end_time - start_time).total_seconds()\n",
    "\n",
    "    # for comparison between frames and events\n",
    "    delta_cols  = (float(dict_event['frames'][-1]['col']) - float(dict_event['frames'][0]['col']))\n",
    "    col_speed   = delta_cols/ duration\n",
    "\n",
    "    delta_rows  = (float(dict_event['frames'][-1]['row']) - float(dict_event['frames'][0]['row']))\n",
    "    row_speed   = delta_rows/ duration\n",
    "\n",
    "\n",
    "    # get the highest observed intensity (and lowest astronomical magnitude)\n",
    "    max_intensity = 0\n",
    "    min_magnitude = 999999\n",
    "    for frame in dict_event['frames']:\n",
    "        current_intensity = int(frame['inten'])\n",
    "        current_magnitude = float(frame['mag'])\n",
    "        if ( current_intensity > max_intensity ):\n",
    "            max_intensity = current_intensity\n",
    "            min_magnitude = current_magnitude\n",
    "\n",
    "    dict_event.update({\n",
    "        'meteor_duration': duration,\n",
    "        'min_magnitude': min_magnitude,\n",
    "        'max_intensity': max_intensity,\n",
    "        'col_speed': col_speed,\n",
    "        'row_speed': row_speed\n",
    "    })\n",
    "    \n",
    "    return dict_event;\n",
    "\n",
    "#RMS uses 256 frame blocks, so we need to check that an event wasn't cut in half\n",
    "def rms_check_if_same_event(prev_event, curr_event):\n",
    "    \"\"\"\n",
    "    How it works:\n",
    "    - make sure the two events are from the same camera\n",
    "    - make sure the two events are from a different file (distinct events)\n",
    "    - make sure that the end of A and the start of B are at a close time (0.5 seconds)\n",
    "    - calculate what the approximate average speed was\n",
    "    - check that the trajectory is rougly the same direction and order of magnitude\n",
    "    \"\"\"\n",
    "    #print('------------------------------------------\\nin >rms_check_if_same_event<')\n",
    "    \n",
    "    # check is same camera\n",
    "    prev_cam = prev_event['file_prefix']\n",
    "    curr_cam = curr_event['file_prefix']\n",
    "    if not prev_cam == curr_cam:\n",
    "        #print('prev_cam = ', prev_cam)\n",
    "        #print('curr_cam = ', curr_cam)\n",
    "        #print('not from same camera - returning False')\n",
    "        return False\n",
    "\n",
    "    # if it is a continuation then it is in a different file\n",
    "    prev_file = prev_event['file_name']\n",
    "    curr_file = curr_event['file_name']\n",
    "    # print('prev_file = ', prev_file)\n",
    "    # print('curr_file = ', curr_file)\n",
    "\n",
    "    if prev_file == curr_file:\n",
    "        #print('from same file - returning False')\n",
    "        return False\n",
    "\n",
    "    # ensure small time difference\n",
    "    prev_end_time   = prev_event['frames'][-1]['timestamp']\n",
    "    curr_start_time = curr_event['frames'][0]['timestamp']\n",
    "    delta_time      = float((curr_start_time - prev_end_time).total_seconds())  #the time elapsed in seconds\n",
    "    #frame_rate      = float(curr_event['fps'])\n",
    "\n",
    "    #max_time_delta = 5.0 / frame_rate   #the number of frames in five seconds\n",
    "    max_time_delta = 0.5   # no more than half a second between frames\n",
    "    #print('delta_time = ', delta_time)\n",
    "    #print('max_time_delta = ', max_time_delta)\n",
    "    if delta_time > max_time_delta :\n",
    "        # print('delta_time too large - returning False')\n",
    "        return False\n",
    "\n",
    "    #print(\"Close Time\")\n",
    "\n",
    "    # check trajectory is as expected\n",
    "\n",
    "    # end of last events (start point) & start of next event (end point)\n",
    "    prev_end_col = float(prev_event['frames'][-1]['col'])\n",
    "    prev_end_row = float(prev_event['frames'][-1]['row'])\n",
    "    curr_start_col = float(curr_event['frames'][0]['col'])\n",
    "    curr_start_row = float(curr_event['frames'][0]['row'])\n",
    "\n",
    "    #get speed between end of prev and start of next\n",
    "    col_change = curr_start_col - prev_end_col\n",
    "    row_change = curr_start_row - prev_end_row\n",
    "    col_frame_speed = col_change / delta_time\n",
    "    row_frame_speed = row_change / delta_time\n",
    "\n",
    "    # what the previously measured speed was\n",
    "    #col_expected_speed = prev_event['col_speed']\n",
    "    #row_expected_speed = prev_event['row_speed']\n",
    "    \n",
    "    # what the speed was at the beginning of the current meteor\n",
    "    end_frame = min(5,len(curr_event['frames']))   #take either the fifth or last frame\n",
    "    if (end_frame < 2):\n",
    "        # print('not enough data in second meteor - returning False')\n",
    "        return False\n",
    "\n",
    "    curr_end_col = float(curr_event['frames'][end_frame-1]['col'])\n",
    "    curr_end_row = float(curr_event['frames'][end_frame-1]['row'])\n",
    "    curr_end_time   = curr_event['frames'][end_frame-1]['timestamp']\n",
    "    curr_delta_time      = float((curr_end_time - curr_start_time).total_seconds())  #the time elapsed in seconds\n",
    "    col_expected_speed = (curr_end_col - curr_start_col) / curr_delta_time\n",
    "    row_expected_speed = (curr_end_row - curr_start_row) / curr_delta_time\n",
    "\n",
    "    # get the fraction of the actual change vs expected change, avoiding errors with low denominators\n",
    "    if (abs(col_expected_speed) < 10.):                \n",
    "        col_frac_change = 1.\n",
    "    else:                \n",
    "        col_frac_change = col_frame_speed / col_expected_speed\n",
    "\n",
    "    if (abs(row_expected_speed) < 10.):                \n",
    "        row_frac_change = 1.\n",
    "    else:                \n",
    "        row_frac_change = row_frame_speed / row_expected_speed\n",
    "\n",
    "    # checks that it is roughly within an expected range\n",
    "    good_col_change = (0.5 < col_frac_change and col_frac_change < 2) \n",
    "    good_row_change = (0.5 < row_frac_change and row_frac_change < 2) \n",
    "\n",
    "    if not( good_col_change and good_row_change ):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "    \n",
    "def rmsdict_to_std(meteor_info: dict, cam_info: dict):\n",
    "\n",
    "    # cam:\n",
    "    # { \n",
    "    #   F_scale, Ho, JD, RA_H, RA_M, RA_S, RA_d, UT_corr, X_res, Y_res, alt_centre, auto_check_fit_refined,\n",
    "    #   az_centre, dec_D, dec_M, dec_S, dec_d, elev, focal_length, fov_h, fov_v, gamma, lat, lon\n",
    "    #   mag_0, mag_lev, mag_lev_stddev, pos_angle_ref, rotation_from_horiz, star_list[]\n",
    "    #   station_code, version, vignetting_coeff, timestamp, file_name\n",
    "    #   x_poly[], x_poly_fwd[], x_poly_rev[], y_poly[], y_poly_fwd[], y_poly_rev[]\n",
    "    # }\n",
    "    #\n",
    "    # meteor:\n",
    "    # [{\n",
    "    # cam, meteor, segments, fps, hnr, mle, bin, pix/fm, rho, phi, \n",
    "    # file_name, file_prefix, timestamp, duration, min_magnitude, max_intensity, \n",
    "    # frames: [{\n",
    "    #     frame, timestamp, col, row, ra, dec, azim, elev, inten, mag\n",
    "    #   }]\n",
    "    # }]\n",
    "    ##\n",
    "    \n",
    "    # Now get metadata\n",
    "    \n",
    "    #location\n",
    "    obs_longitude = float(cam_info['lon'])\n",
    "    obs_latitude  = float(cam_info['lat'])\n",
    "    obs_elevation = float(cam_info['elev'])\n",
    "    \n",
    "    #camera station site name\n",
    "    telescope  = cam_info['station_code']     #no spaces or special characters\n",
    "    location   = telescope\n",
    "\n",
    "    #observer and instrument\n",
    "    origin    = \"RMS\" + '_Ver_'+ str(cam_info['version'])  # or other formal network names\n",
    "    observer  = cam_info['station_code']\n",
    "    instrument = 'PiCam'\n",
    "    lens = ''\n",
    "    image_file = meteor_info['file_name']\n",
    "    astrometry_number_stars = len(cam_info['star_list'])\n",
    "    cx = int(cam_info['X_res'])\n",
    "    cy = int(cam_info['Y_res'])\n",
    "     \n",
    "    # calculate event timings - file timestamp\n",
    "    # timestamp = cam_info['timestamp']\n",
    "    # head = float(meteor_info['frames'][0]['frame']) \n",
    "    # print('head = ', head )\n",
    "    \n",
    "    # frame rate and beginning of clip\n",
    "    frame_rate = float(meteor_info['fps'])\n",
    "    isodate_start_time = meteor_info['frames'][ 0]['timestamp']\n",
    "    isodate_end_time   = meteor_info['frames'][-1]['timestamp']\n",
    "    isodate_midpoint_time = isodate_start_time + (isodate_end_time - isodate_start_time)/2\n",
    "    isodate_start = isodate_start_time.strftime(ISO_FORMAT)   \n",
    "    isodate_end = isodate_end_time.strftime(ISO_FORMAT)   \n",
    "    isodate_midpoint = isodate_midpoint_time.strftime(ISO_FORMAT)   \n",
    "    meteor_duration = meteor_info['meteor_duration']\n",
    "\n",
    "   \n",
    "   # construction of the metadata dictionary\n",
    "    meta_dic = {\n",
    "        'obs_latitude': obs_latitude,\n",
    "        'obs_longitude': obs_longitude,\n",
    "        'obs_elevation': obs_elevation,\n",
    "        'origin': origin,\n",
    "        'location': location,\n",
    "        'telescope': telescope,\n",
    "        'camera_id': telescope,\n",
    "        'observer': observer,\n",
    "        'comment': '',\n",
    "        'instrument': instrument,\n",
    "        'lens': lens,\n",
    "        'cx' : cx,     \n",
    "        'cy' : cy,     \n",
    "        'photometric_band': 'Unknown',\n",
    "        'image_file' : image_file,\n",
    "        'isodate_start_obs': str(isodate_start),\n",
    "        'isodate_calib' : str(isodate_midpoint),\n",
    "        'exposure_time': meteor_duration,\n",
    "        'astrometry_number_stars' : astrometry_number_stars,\n",
    "        # 'photometric_zero_point': float(cam_info['mag_lev']),\n",
    "        # 'photometric_zero_point_uncertainty': float(cam_info['mag_lev_stddev']),\n",
    "        'mag_label': 'mag',\n",
    "        'no_frags': 1,\n",
    "        'obs_az': float(cam_info['az_centre']),     \n",
    "        'obs_ev': float(cam_info['alt_centre']),     \n",
    "        'obs_rot': float(cam_info['rotation_from_horiz']),     \n",
    "        'fov_horiz': float(cam_info['fov_h']),     \n",
    "        'fov_vert': float(cam_info['fov_v']),     \n",
    "    }\n",
    "    \n",
    "    # initialise table\n",
    "    ttt = Table()        \n",
    "    #Update the table metadata\n",
    "    ttt.meta.update(meta_dic)   \n",
    "   \n",
    "\n",
    "    #create time and main data arrays\n",
    "    # Datetime is ISO 8601 UTC format\n",
    "    datetime_array = []\n",
    "    # Azimuth are East of North, in degrees\n",
    "    azimuth_array  = []\n",
    "    # Altitudes are geometric (not apparent) angles above the horizon, in degrees\n",
    "    altitude_array = []\n",
    " \n",
    "    #right ascension and declination coordinates\n",
    "    ra_array  = []\n",
    "    dec_array = []\n",
    "    x_array = []     \n",
    "    y_array = []     \n",
    "    mag_array = []    \n",
    "    \n",
    "    nlines = len(meteor_info[\"frames\"])\n",
    "    #print('nlines= ',nlines)\n",
    "    \n",
    "    for i in range(nlines):\n",
    "        obs = meteor_info[\"frames\"][i]\n",
    "        \n",
    "        azimuth_array.append(  float(obs['azim']) )\n",
    "        altitude_array.append( float(obs['elev']) )\n",
    "        datetime_array.append( obs['timestamp'].strftime(ISO_FORMAT)   )\n",
    "        ra_array.append( float(obs['ra']) )\n",
    "        dec_array.append( float(obs['ra']) )\n",
    "        x_array.append( float(obs['col']))     \n",
    "        y_array.append( float(obs['row']))     \n",
    "        mag_array.append( float(obs['mag']))   \n",
    "        \n",
    "    \n",
    "    ## Populate the table with the data created to date\n",
    "    # create columns\n",
    "    ttt['datetime'] = datetime_array\n",
    "    ttt['ra']   = ra_array  * u.degree\n",
    "    ttt['dec']  = dec_array * u.degree\n",
    "    ttt['azimuth']  = azimuth_array  * u.degree\n",
    "    ttt['altitude'] = altitude_array * u.degree    \n",
    "    ttt['mag']  =   mag_array     \n",
    "    ttt['x_image']  = x_array     \n",
    "    ttt['y_image']  = x_array     \n",
    "    \n",
    "    return ttt;\n",
    "\n",
    "    \n",
    "def rms_dict_list_to_std(rms_meteor_dict_list, rms_cams_info):\n",
    "    # list of cameras we have:\n",
    "    cam_list = []\n",
    "    for cam in rms_cams_info:\n",
    "        cam_list.append(cam)\n",
    "    \n",
    "    #get an astropy table list\n",
    "    ttt_list = []\n",
    "    for meteor_info in rms_meteor_dict_list:\n",
    "        # get info for each\n",
    "        if not meteor_info:\n",
    "            print(\"Empty Entry : \", meteor_info, \" - Likely due to merging\")\n",
    "            continue\n",
    "            \n",
    "        file_prefix = meteor_info['file_prefix']\n",
    "        cam_info    = find_most_recent_cam_calibration( rms_cams_info[file_prefix] , meteor_info['timestamp'] )\n",
    "\n",
    "        # convert and add to list\n",
    "        ttt1 = rmsdict_to_std(meteor_info, cam_info)\n",
    "        ttt2 = std_timeshift(ttt1,RMS_DELAY)\n",
    "        ttt_list.append(ttt2)\n",
    "\n",
    "    return ttt_list\n",
    "    \n",
    "    \n",
    "def rms_to_std(rms_meteor_text, rms_cams_dict):\n",
    "    \n",
    "    rms_meteor_dict_list = rms_to_dict(rms_meteor_text);\n",
    "    \n",
    "    ttt_list = rms_dict_list_to_std(rms_meteor_dict_list, rms_cams_dict)\n",
    "    \n",
    "    return ttt_list, len(ttt_list);\n",
    "\n",
    "\n",
    "def rms_json_to_std(json_data, lname):\n",
    "    # This reads a string which is in RMS json format and converts it to standard format\n",
    "\n",
    "    # Set up arrays for point observation data\n",
    "    datetime_array = []\n",
    "    datestr_array = []\n",
    "    azimuth_array = []\n",
    "    altitude_array = []\n",
    "    ra_array = []\n",
    "    dec_array = []\n",
    "    mag_array = []\n",
    "    x_image_array = []\n",
    "    y_image_array = []\n",
    "    JD_array = []\n",
    "    \n",
    "\n",
    "    # Standard  spec\n",
    "    instrument = ''\n",
    "    lens = ''\n",
    "    cx = 1920\n",
    "    cy = 1080\n",
    "\n",
    "    # start of J2000 epoch\n",
    "    ts = datetime.strptime(\"2000-01-01T12:00:00.000\",ISO_FORMAT)\n",
    "    start_epoch = datetime2JD(ts)\n",
    "   \n",
    "    # Check the json data to see which format it is in, and extract information accordingly.  \n",
    "    \n",
    "    if 'centroids' in json_data :\n",
    "        # The February 2021 RMS json format\n",
    "        # if lname.endswith(\"reduced.json\"):\n",
    "        # for key_name in json_data.keys(): \n",
    "        #    print(key_name)\n",
    "        #\n",
    "       \n",
    "        jdt_ref = float(json_data['jdt_ref'])\n",
    "        frame_rate = float(json_data['fps'])\n",
    "        no_lines = len(json_data['centroids'])\n",
    "        print('no_lines = ',no_lines)\n",
    "\n",
    "        #   \"station\": {\n",
    "        #       \"elev\": 63.0,\n",
    "        #       \"lat\": 51.53511,\n",
    "        #        \"lon\": -2.14857,\n",
    "        #       \"station_id\": \"UK000X\"\n",
    "        obs_latitude = float(json_data['station']['lat'])  \n",
    "        obs_longitude = float(json_data['station']['lon'])\n",
    "        obs_elevation = float(json_data['station']['elev'])  \n",
    "        location = str(json_data['station']['station_id'])\n",
    "        telescope = ''\n",
    "        camera_id = location\n",
    "        observer = ''\n",
    "        rstars = 0\n",
    "\n",
    "        for i in range(no_lines):\n",
    "            f_data = json_data['centroids'][i]\n",
    "            #\"centroids_labels\": [\n",
    "            # \"Time (s)\",    [0]\n",
    "            # \"X (px)\",      [1]\n",
    "            # \"Y (px)\",      [2]\n",
    "            # \"RA (deg)\",    [3]\n",
    "            # \"Dec (deg)\",   [4]\n",
    "            # \"Summed intensity\",  [5]\n",
    "            # \"Magnitude\"     [6]\n",
    "\n",
    "            # 5.451308905560867,\n",
    "            # 1018.0993786888196,\n",
    "            # 361.8849779477523,\n",
    "            # 338.9399709902407,\n",
    "            # 76.4566600907301,\n",
    "            # 1,\n",
    "            # 9.592039852289648\n",
    "    \n",
    "            # date_str = f_data[0].replace(' ','T')\n",
    "            # date_time = datetime.strptime(date_str,ISO_FORMAT)\n",
    "            #print('i=',i,' date_str =',date_str, ' date_time =',date_time)\n",
    "            JD = jdt_ref + float(f_data[0])/ 86400.0\n",
    "            JD_array.append(JD)\n",
    "            tm = Time(str(JD), format='jd')\n",
    "            date_time = tm.strftime(ISO_FORMAT) \n",
    "            # print('tm = ',tm,', date_time = ',date_time)\n",
    "            \n",
    "            ra = float(f_data[3])\n",
    "            dec = float(f_data[4])\n",
    "\n",
    "            # RA and DEC are in J2000 epoch.  Precess to epoch of date, then convert to Az and Alt using RMS code\n",
    "            temp_ra, temp_dec = equatorialCoordPrecession(start_epoch, JD, ra, dec)  \n",
    "            temp_azim, temp_elev = raDec2AltAz(temp_ra, temp_dec, JD, obs_latitude, obs_longitude)\n",
    "            \n",
    "            datetime_array.append(date_time)\n",
    "            ra_array.append(ra)\n",
    "            dec_array.append(dec)\n",
    "            azimuth_array.append(temp_azim)\n",
    "            altitude_array.append(temp_elev)\n",
    "            mag_array.append(float(f_data[6]))\n",
    "            x_image_array.append(float(f_data[1]))\n",
    "            y_image_array.append(float(f_data[2]))\n",
    " \n",
    "        \n",
    "        # meteor_duration = datetime_array[-1] - datetime_array[0]\n",
    "        print('frame_rate = ', frame_rate)\n",
    "        meteor_duration_float = 86400.0 * (JD_array[-1] - JD_array[0])\n",
    "        print('meteor_duration = ', meteor_duration_float)\n",
    "     \n",
    "    \n",
    "        time_step = -float(json_data['centroids'][0][0])   # time of first frame \n",
    "        tm = Time(str(jdt_ref), format='jd')\n",
    "        isodate_start_time = tm.strftime(ISO_FORMAT) \n",
    "        print('isodate_start_time = ', isodate_start_time)\n",
    "        isodate_start = tm.strftime(ISO_FORMAT)   \n",
    "        \n",
    "        JD_mid = jdt_ref + 0.5 * (JD_array[-1] - jdt_ref)\n",
    "        print(\"JD_mid = \",JD_mid)\n",
    "        tm = Time(str(JD_mid), format='jd')\n",
    "        isodate_midpoint = tm.strftime(ISO_FORMAT) \n",
    "        print('isodate_midpoint = ', isodate_midpoint)\n",
    " \n",
    "    \n",
    "        ##############################\n",
    "        ##############################\n",
    "        ##############################\n",
    "        ##############################\n",
    "        ##############################\n",
    "        ##############################\n",
    "        \n",
    "    \n",
    "        \n",
    "        meta_dic = {'obs_latitude': obs_latitude,  \n",
    "           'obs_longitude': obs_longitude,  \n",
    "           'obs_elevation': obs_elevation,  \n",
    "           'origin': 'RMS',\n",
    "           'location': location,\n",
    "           'telescope': telescope,\n",
    "           'camera_id': camera_id,\n",
    "           'observer': observer,\n",
    "           'comment': '',            \n",
    "           'instrument': instrument,\n",
    "           'lens': lens,\n",
    "           'cx' : cx,     \n",
    "           'cy' : cy,     \n",
    "           'photometric_band' : 'Unknown',     \n",
    "           'image_file' : 'Unknown',\n",
    "           'isodate_start_obs': str(isodate_start),  \n",
    "           'isodate_calib' : str(isodate_midpoint), \n",
    "           'exposure_time': meteor_duration_float,    \n",
    "           'astrometry_number_stars' : rstars,\n",
    "           #'photometric_zero_point': 0.0,    \n",
    "           #'photometric_zero_point_uncertainty': 0.0,\n",
    "           'mag_label': 'mag',     \n",
    "           'no_frags': 1,\n",
    "           'obs_az': 0.0,     \n",
    "           'obs_ev': 0.0,     \n",
    "           'obs_rot': 0.0,     \n",
    "           'fov_horiz': 0.0,     \n",
    "           'fov_vert': 0.0,     \n",
    "           }\n",
    "\n",
    "\n",
    "    else:        \n",
    "        print('\\n RMS json format not recognised')\n",
    "        return([], 0);\n",
    "        \n",
    "    \n",
    "    # initialise table\n",
    "    ttt = Table()        \n",
    "    #Update the table metadata\n",
    "    ttt.meta.update(meta_dic)   \n",
    "    \n",
    "    ttt['datetime'] = datetime_array\n",
    "    ttt['ra'] = ra_array\n",
    "    ttt['dec'] = dec_array\n",
    "    ttt['azimuth'] = azimuth_array\n",
    "    ttt['altitude'] = altitude_array\n",
    "    ttt['mag'] = mag_array\n",
    "    ttt['x_image'] = x_image_array\n",
    "    ttt['y_image'] = y_image_array\n",
    "    \n",
    "    return([ttt], 1);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAMS functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cams_camera_txt( _camera_file_path )\n",
    "# #rms_to_dict()\n",
    "# #camsdict_to_astropy_table(meteor_info: dict, cam_info: dict):\n",
    "# #cams_dict_list_to_astropy_tables(rms_meteor_dict_list, cams_camera_info):\n",
    "# cams_to_std(cams_meteor_text, cams_cameras_dict):\n",
    "\n",
    "\n",
    "def cams_camera_txt(_camera_file_path):\n",
    "     \n",
    "    #extract json data\n",
    "    _cal_txt = open(_camera_file_path).read()\n",
    "    _cal_lines = _cal_txt.split(\"\\n\")\n",
    "    \n",
    "    cam_dict = {}\n",
    "    \n",
    "    #test if a line is \"something = value\"\n",
    "    equals_test = \"(.*)=(.*)\"\n",
    "    \n",
    "    cal_date, cal_time = False, False\n",
    "    \n",
    "    for cal_line in _cal_lines :\n",
    "        if not regex.match(equals_test, cal_line):\n",
    "            continue\n",
    "                \n",
    "        temp_regex_results = regex.search(equals_test, cal_line)\n",
    "        cal_term       = temp_regex_results[1].strip()\n",
    "        cal_term_value = temp_regex_results[2].strip()\n",
    "        L = len(cal_term_value)\n",
    "        \n",
    "        print(cal_term, \" \\t:\", cal_term_value)    \n",
    "        \n",
    "        if regex.match(\"\\d+\", cal_term_value) and len(regex.search(\"\\d+\", cal_term_value)[0]) == L:\n",
    "            cam_dict.update({ cal_term: int(cal_term_value) })\n",
    "            print(\"Integer detected\")\n",
    "            continue\n",
    "        \n",
    "        if regex.match(\"[0-9.+-]+\", cal_term_value) and len(regex.search(\"[0-9.+-]+\", cal_term_value)[0]) == L:\n",
    "            cam_dict.update({ cal_term: float(cal_term_value) })\n",
    "            print(\"Float detected\")\n",
    "            continue\n",
    "        \n",
    "        if regex.match(\"\\d{2}/\\d{2}/\\d{4}\", cal_term_value):\n",
    "            cal_date_str = regex.search(\"\\d{2}/\\d{2}/\\d{4}\", cal_term_value)[0]\n",
    "            cal_date = datetime.strptime(cal_date_str,\"%m/%d/%Y\").strftime(\"%Y-%m-%d\")\n",
    "            print(\"Date detected\")\n",
    "            continue\n",
    "        \n",
    "        if regex.match(\"\\d{2}:\\d{2}:\\d{2}.\\d{3}\", cal_term_value):\n",
    "            cal_time = regex.search(\"\\d{2}:\\d{2}:\\d{2}.\\d{3}\", cal_term_value)[0]\n",
    "            print(\"Time detected\")\n",
    "            continue\n",
    "            \n",
    "        if cal_term == \"FOV dimension hxw (deg)\":\n",
    "            cal_fov_hw = regex.search(\"([+\\-0-9.]+)\\s*x\\s*([+\\-0-9.]+)\", cal_term_value)\n",
    "            print(cal_fov_hw)\n",
    "            cam_dict.update({\n",
    "                \"FOV dimension hxw (deg)\": cal_fov_hw[0],\n",
    "                'FOV height (deg)' : float(cal_fov_hw[1]),\n",
    "                'FOV width (deg)'  : float(cal_fov_hw[2]),\n",
    "            })\n",
    "            continue\n",
    "            \n",
    "        cam_dict.update({cal_term: cal_term_value})\n",
    "                        \n",
    "    if cal_date and cal_time:\n",
    "        cal_timestamp_string = cal_date + \"T\" + cal_time + \"000\"\n",
    "        cal_timestamp = datetime.strptime(cal_timestamp_string, ISO_FORMAT)\n",
    "        cam_dict.update({\"timestamp\": cal_timestamp})\n",
    "            \n",
    "    print(\"Got camera data \")\n",
    "    \n",
    "    return cam_dict\n",
    "        \n",
    "def camsdict_to_astropy_table(meteor_info: dict, cam_info: dict):\n",
    "\n",
    "    # cam:\n",
    "    # \n",
    "    \"\"\"\n",
    "    {\n",
    "     'Camera number': 3814,\n",
    "     'Longitude +west (deg)': -5.39928,\n",
    "     'Latitude +north (deg)': 49.81511,\n",
    "     'Height above WGS84 (km)': 0.4444,\n",
    "     'FOV height (deg)'\n",
    "     'FOV width (deg)'\n",
    "     'FOV dimension hxw (deg)': '46.93 x   88.25',\n",
    "     'Plate scale (arcmin/pix)': 3.948,\n",
    "     'Plate roll wrt Std (deg)': 350.213,\n",
    "     'Cam tilt wrt Horiz (deg)': 2.656,\n",
    "     'Frame rate (Hz)': 25.0,\n",
    "     'Cal center RA (deg)': 50.593,\n",
    "     'Cal center Dec (deg)': 74.131,\n",
    "     'Cal center Azim (deg)': 347.643,\n",
    "     'Cal center Elev (deg)': 36.964,\n",
    "     'Cal center col (colcen)': 640.0,\n",
    "     'Cal center row (rowcen)': 360.0,\n",
    "     'Cal fit order': 201,\n",
    "     'Camera description': 'None',\n",
    "     'Lens description': 'None',\n",
    "     'Focal length (mm)': 0.0,\n",
    "     'Focal ratio': 0.0,\n",
    "     'Pixel pitch H (um)': 0.0,\n",
    "     'Pixel pitch V (um)': 0.0,\n",
    "     'Spectral response B': 0.45,\n",
    "     'Spectral response V': 0.7,\n",
    "     'Spectral response R': 0.72,\n",
    "     'Spectral response I': 0.5,\n",
    "     'Vignetting coef(deg/pix)': 0.0,\n",
    "     'Gamma': 1.0,\n",
    "     'Xstd, Ystd': 'Radialxy2Standard( col, row, colcen, rowcen, Xcoef, Ycoef )',\n",
    "     'x': 'col - colcen',\n",
    "     'y': 'rowcen - row',\n",
    "     'Mean O-C': '0.000 +-   0.000 arcmin',\n",
    "     'Magnitude': '-2.5 ( C + D (logI-logVig) )   fit logFlux vs. Gamma (logI-logVig), mV <  6.60',\n",
    "     'A': 10.0,\n",
    "     'B': -2.5,\n",
    "     'C': -4.0,\n",
    "     'D': 1.0,\n",
    "     'logVig': 'log( cos( Vignetting_coef * Rpixels * pi/180 )^4 )',\n",
    "     'timestamp': datetime.datetime(2019, 5, 14, 20, 56, 33, 531000)\n",
    "    }\n",
    "    \"\"\"\n",
    "    #\n",
    "    # meteor:\n",
    "    # [{\n",
    "    # cam, meteor, segments, fps, hnr, mle, bin, pix/fm, rho, phi, \n",
    "    # file_name, file_prefix, timestamp, duration, min_magnitude, max_intensity, \n",
    "    # frames: [{\n",
    "    #     frame, timestamp, col, row, ra, dec, azim, elev, inten, mag\n",
    "    #   }]\n",
    "    # }]\n",
    "    ##\n",
    "    \n",
    "    # Now get metadata\n",
    "    \n",
    "    #location\n",
    "    obs_longitude = float(cam_info['Longitude +west (deg)'])\n",
    "    obs_latitude  = float(cam_info['Latitude +north (deg)'])\n",
    "    obs_elevation = 1000 * float(cam_info['Height above WGS84 (km)']) # to metres\n",
    "    \n",
    "    \n",
    "    #camera station site name\n",
    "    location   = str(cam_info['Camera number'])\n",
    "    telescope  = str(cam_info['Camera number']).zfill(6) #no spaces or special characters\n",
    "\n",
    "    #observer and instrument\n",
    "    origin    = \"CAMS\"  # or other formal network names\n",
    "    observer  = str(cam_info['Camera number']).zfill(6)\n",
    "    instrument = cam_info['Camera description']\n",
    "    lens = cam_info['Lens description']\n",
    "    image_file = meteor_info['file_name']\n",
    "    astrometry_number_stars = 0\n",
    "    cx = 2 * int(cam_info['Cal center col (colcen)'])\n",
    "    cy = 2 * int(cam_info['Cal center row (rowcen)'])\n",
    "     \n",
    "    # calculate event timings - file timestamp\n",
    "    timestamp = cam_info['timestamp'].strftime(ISO_FORMAT)[:-3]\n",
    "    \n",
    "    # frame rate and beginning of clip\n",
    "    frame_rate = float(meteor_info['fps'])\n",
    "    meteor_duration = meteor_info['meteor_duration']\n",
    "    isodate_start_time = meteor_info['frames'][ 0]['timestamp']\n",
    "    isodate_end_time   = meteor_info['frames'][-1]['timestamp']\n",
    "    isodate_midpoint_time = isodate_start_time + (isodate_end_time - isodate_start_time)/2\n",
    "    isodate_start = isodate_start_time.strftime(ISO_FORMAT)   \n",
    "    isodate_end = isodate_end_time.strftime(ISO_FORMAT)   \n",
    "    isodate_midpoint = isodate_midpoint_time.strftime(ISO_FORMAT)   \n",
    "\n",
    "    \n",
    "    \n",
    "   # construction of the metadata dictionary\n",
    "    meta_dic = {\n",
    "        'obs_latitude': obs_latitude,\n",
    "        'obs_longitude': obs_longitude,\n",
    "        'obs_elevation': obs_elevation,\n",
    "        'origin': origin,\n",
    "        'location': location,\n",
    "        'telescope': telescope,\n",
    "        'camera_id': telescope,\n",
    "        'observer': observer,\n",
    "        'comment': '',            \n",
    "        'instrument': instrument,\n",
    "        'lens': lens,\n",
    "        'cx' : cx,     \n",
    "        'cy' : cy,     \n",
    "        'photometric_band' : 'Unknown',     \n",
    "        'image_file' : image_file,\n",
    "        'isodate_start_obs': isodate_start,\n",
    "        'isodate_calib' : isodate_midpoint,\n",
    "        'exposure_time': meteor_duration,\n",
    "        'astrometry_number_stars' : astrometry_number_stars,\n",
    "        #'photometric_zero_point': 0.0,\n",
    "        #'photometric_zero_point_uncertainty': 0.0,\n",
    "        'mag_label': 'mag',\n",
    "        'no_frags': 1,\n",
    "        'obs_az': float(cam_info['Cal center Azim (deg)']),     \n",
    "        'obs_ev': float(cam_info['Cal center Elev (deg)']),     \n",
    "        'obs_rot': float(cam_info['Cam tilt wrt Horiz (deg)']),     \n",
    "        'fov_horiz': float(cam_info['FOV width (deg)']),     \n",
    "        'fov_vert': float(cam_info['FOV height (deg)']),     \n",
    "    }\n",
    "    \n",
    "    # initialise table\n",
    "    ttt = Table()        \n",
    "    #Update the table metadata\n",
    "    ttt.meta.update(meta_dic)   \n",
    "   \n",
    "\n",
    "    #create time and main data arrays\n",
    "    # Datetime is ISO 8601 UTC format\n",
    "    datetime_array = []\n",
    "    # Azimuth are East of North, in degrees\n",
    "    azimuth_array  = []\n",
    "    # Altitudes are geometric (not apparent) angles above the horizon, in degrees\n",
    "    altitude_array = []\n",
    " \n",
    "    #right ascension and declination coordinates\n",
    "    ra_array  = []\n",
    "    dec_array = []    \n",
    "    x_array = []     \n",
    "    y_array = []      \n",
    "    mag_array = []    \n",
    "\n",
    "    \n",
    "    nlines = len(meteor_info[\"frames\"])\n",
    "    print('nlines= ',nlines)\n",
    "    \n",
    "    for i in range(nlines):\n",
    "        obs = meteor_info[\"frames\"][i]\n",
    "        \n",
    "        azimuth_array.append(  float(obs['azim']) )\n",
    "        altitude_array.append( float(obs['elev']) )\n",
    "        datetime_array.append( obs['timestamp'].strftime(ISO_FORMAT)   )\n",
    "        ra_array.append( float(obs['ra']) )\n",
    "        dec_array.append( float(obs['dec']) )\n",
    "        x_array.append( float(obs['col']))     \n",
    "        y_array.append( float(obs['row']))     \n",
    "        mag_array.append( float(obs['mag']))   \n",
    "    \n",
    "    ## Populate the table with the data created to date\n",
    "    # create columns\n",
    "    ttt['datetime'] = datetime_array\n",
    "    ttt['ra']   = ra_array  * u.degree\n",
    "    ttt['dec']  = dec_array * u.degree    \n",
    "    ttt['azimuth']  = azimuth_array  * u.degree\n",
    "    ttt['altitude'] = altitude_array * u.degree    \n",
    "    ttt['mag']  =   mag_array     \n",
    "    ttt['x_image']  = x_array     \n",
    "    ttt['y_image']  = x_array     \n",
    "    \n",
    "    return ttt;\n",
    "\n",
    "    \n",
    "def cams_dict_list_to_std(rms_meteor_dict_list, cams_camera_info):\n",
    "    #get an astropy table list\n",
    "    ttt_list = []\n",
    "    for meteor_info in rms_meteor_dict_list:\n",
    "        # get info for each\n",
    "        if not meteor_info:\n",
    "            print(\"Empty Entry : \", meteor_info, \" - Likely due to merging\")\n",
    "            continue\n",
    "            \n",
    "        file_prefix = meteor_info['file_prefix']\n",
    "        \n",
    "        # convert and add to list\n",
    "        singular_ttt = camsdict_to_astropy_table(meteor_info, cams_camera_info)\n",
    "        ttt_list.append(singular_ttt)\n",
    "\n",
    "    return ttt_list\n",
    "    \n",
    "    \n",
    "def cams_to_std(cams_meteor_text, cams_cameras_dict):\n",
    "    \n",
    "    meteor_dict_list = rms_to_dict(cams_meteor_text);\n",
    "    \n",
    "    ttt_list = cams_dict_list_to_std( meteor_dict_list, cams_cameras_dict)\n",
    "    \n",
    "    return ttt_list, len(ttt_list);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetRec functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# List of info in .log in _metrec_cfg\n",
    "\n",
    "AutoConfiguration \t -  yes\n",
    "FrameGrabberType \t -  Meteor II\n",
    "FrameGrabberDeviceNumber \t -  1\n",
    "VideoSignalType \t -  PAL\n",
    "InterlacedVideo \t -  no\n",
    "TimeBase \t -  current time\n",
    "TimeDriftCorrection \t -  0.0 s/h\n",
    "TimeZoneCorrection \t -  0 h\n",
    "DSTCorrection \t -  no\n",
    "DateBase \t -  current date\n",
    "DateCorrection \t -  yes\n",
    "RecognitionEndTime \t -  6 h 30 m 0 s\n",
    "AutoRestart \t -  no\n",
    "QuitBehaviour \t -  quit without confirmation\n",
    "WaitForDusk \t -  no\n",
    "MaximumSolarAltitude \t -  -16 $\n",
    "MinimumLunarDistance \t -  0 $\n",
    "PosDriftCorrection \t -  X/Y\n",
    "PosDriftHistory \t -  metrec.pos\n",
    "FrameBufferCount \t -  300 frame(s)\n",
    "DelayTime \t -  0 ms\n",
    "DisplayRefreshRate \t -  2\n",
    "InternalResolution \t -  max\n",
    "MeteorElongation \t -  1\n",
    "StartThreshold \t -  1.50\n",
    "ConstantThreshold \t -  no\n",
    "RecognitionThreshold \t -  0.85\n",
    "FloorThreshold \t -  0.50\n",
    "ThresholdHistory \t -  metrec.thr\n",
    "FlashThreshold \t -  20\n",
    "FlashRecoveryFrameCount \t -  50 frame(s)\n",
    "SaveFlashImage \t -  no\n",
    "SaveBackgroundRate \t -  never\n",
    "MinimumFrameCount \t -  3 frame(s)\n",
    "Beep \t -  no\n",
    "SendSerialPing \t -  yes\n",
    "SerialPingPort \t -  1\n",
    "SerialPingType \t -  ABEI\n",
    "MinimumMeteorVelocity \t -  1.0 $/s\n",
    "MaximumMeteorVelocity \t -  50.0 $/s\n",
    "PositionAngleOffset \t -  0 $\n",
    "UseInputMask     -  yes\n",
    "InputMask        -  c:\\cilbo\\metrec\\config\\ICC7mask.bmp\n",
    "DarkField        -  dark.bmp\n",
    "UseOldFlatField  -  no\n",
    "NewFlatField \t -  metrec.ffd\n",
    "FlatFieldSmooth \t -  2\n",
    "FlatFieldSmoothDir \t -  symmetric\n",
    "SensitivityImage \t -  metrec.bmp\n",
    "TracingImage \t -  ????????.bmp\n",
    "TimeStamp \t -  date and time\n",
    "TimeStampXPosition \t -  384\n",
    "TimeStampYPosition \t -  288\n",
    "SaveSingleFrames \t -  bright only\n",
    "SingleFrameBrightness \t -  0.0\n",
    "SingleFrameDuration \t -  0.5\n",
    "SaveMeteorBand \t -  yes\n",
    "SaveSumImage \t -  yes\n",
    "SaveMeteorData \t -  yes\n",
    "SavePreFrameCount \t -  3 frame(s)\n",
    "SavePostFrameCount \t -  3 frame(s)\n",
    "SavePostFrameBright \t -  30 frame(s)\n",
    "RealTimeFluxUpload \t -  no\n",
    "CameraName \t -  ICC7\n",
    "BaseDirectory \t -  c:\\cilbo\\data\\ICC7\\\n",
    "FileNameRule \t -  hhmmssff.bmp\n",
    "ClockSync \t -  no\n",
    "EquatorialCoordinates \t -  yes\n",
    "ReferenceStars \t -  20190903.ref\n",
    "MaximumMeteorTilt \t -  0 $\n",
    "MaximumMeteorShift \t -  0 $\n",
    "CreatePosDatEntry \t -  yes\n",
    "Operation mode \t -  unguided\n",
    "Reference date \t -  2019/09/03\n",
    "Reference time \t -  23:00:00\n",
    "Site code \t -  15556\n",
    "Longitude \t -  -16.509171 $\n",
    "Latitude \t -  28.298901 $\n",
    "Altitude \t -  2400 m\n",
    "Noise Level \t -  5.0\n",
    "Maximum Star Diameter \t -  4.0\n",
    "Minimum Star Diameter \t -  1.0\n",
    "Video brightness \t -  128\n",
    "Video contrast \t -  128\n",
    "Gamma correction \t -  1.00\n",
    "Order of plate constants \t -  3\n",
    "Center of plate RA \t -  18.0080 h\n",
    "Center of plate DE \t -  34.5535 $\n",
    "Center of plate Alt \t -  54.6 $\n",
    "Center of plate Az \t -  290.8 $\n",
    "Size of field of view \t -  30.5 x 23.0 $\n",
    "O-C RefStar1 \t -  msqe= 0.55'  l1o= 0.63'  -0.00 mag  (B-V= 1.40 mag)\n",
    "...\n",
    "O-C RefStar51 \t -  msqe= 1.81'  l1o= 2.08'   0.10 mag  (B-V= 1.10 mag)\n",
    "Mean Squared O-C \t -  msqe= 1.66'  l1o= 2.04'   0.41 mag\n",
    "Photometric equation \t -  -2.326 log(pixelsum) + 8.390\n",
    "Color index correction \t -  -0.127 (B-V) + 0.063\n",
    "Nominal lim. magnitude \t -  5.7 mag\n",
    "Total collection area \t -  682 deg^2 / 4196 km^2 @ 100 km alt\n",
    "Corrected total collection area \t -  2377 km^2\n",
    "Number of active meteor showers (2019/11/01) \t -  3\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# List of info in inf\n",
    "\n",
    "'#', 'time', 'bright', 'x', 'y', 'alpha', 'delta', 'c_x', 'c_y', 'c_alpha', 'c_delta', 'use', 'timestamp'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def metrec_to_standard(inf, log):\n",
    "\n",
    "    cfg = log._metrec_cfg\n",
    "    \n",
    "    def getFloat(numstr):\n",
    "        return float( regex.match('[+\\-0-9.]+',numstr)[0] )      \n",
    "    \n",
    "    #location\n",
    "    obs_longitude = getFloat(cfg['Longitude'])\n",
    "    obs_latitude  = getFloat(cfg['Latitude'])\n",
    "    obs_elevation = getFloat(cfg['Altitude'])\n",
    "\n",
    "    #camera station site name\n",
    "    location   = str(cfg['Site code'])\n",
    "    telescope  = str(cfg['CameraName']).zfill(6) #no spaces or special characters\n",
    "\n",
    "    #observer and instrument\n",
    "    origin     = \"MetRec\"  # or other formal network names\n",
    "    observer   = cfg['CameraName']\n",
    "    instrument = cfg['CameraName']\n",
    "    lens       = 'unknown'\n",
    "    image_file = inf.path\n",
    "    astrometry_number_stars = 0\n",
    "    \n",
    "    if cfg['TimeStamp'] == 'none':\n",
    "        cx = 0\n",
    "        cy = 0\n",
    "    else:    \n",
    "        cx = int(cfg['TimeStampXPosition'])\n",
    "        cy = int(cfg['TimeStampYPosition'])\n",
    "    \n",
    "    \n",
    "    # calculate event timings - file timestamp\n",
    "    timestamp = inf['timestamp'][0]\n",
    "    \n",
    "    meteor_duration    = inf['timestamp'][0]\n",
    "    isodate_start = inf['timestamp'][0]\n",
    "    isodate_end   = inf['timestamp'][-1]\n",
    "    start_datetime = datetime.strptime( isodate_start, ISO_FORMAT )\n",
    "    end_datetime   = datetime.strptime( isodate_end,   ISO_FORMAT )\n",
    "    meteor_duration    = (end_datetime - start_datetime)\n",
    "\n",
    "    isodate_midpoint_time = start_datetime + meteor_duration/2\n",
    "    isodate_midpoint = isodate_midpoint_time.strftime(ISO_FORMAT)   \n",
    "    \n",
    "    meteor_duration = meteor_duration.total_seconds()\n",
    "\n",
    "    # get FOV x and y\n",
    "    cfg_fov = regex.search(\"([+\\-0-9.]+)\\s*x\\s*([+\\-0-9.]+)\", cfg['Size of field of view'])\n",
    "    \n",
    "   # construction of the metadata dictionary\n",
    "    meta_dic = {\n",
    "        'obs_latitude': obs_latitude,\n",
    "        'obs_longitude': obs_longitude,\n",
    "        'obs_elevation': obs_elevation,\n",
    "        'origin': origin,\n",
    "        'location': location,\n",
    "        'telescope': telescope,\n",
    "        'camera_id': telescope,\n",
    "        'observer': observer,\n",
    "        'comment': '',            \n",
    "        'instrument': instrument,\n",
    "        'lens': lens,\n",
    "        'cx' : cx,     \n",
    "        'cy' : cy,     \n",
    "        'photometric_band' : 'Unknown',     \n",
    "        'image_file' : image_file,\n",
    "        'isodate_start_obs': isodate_start,\n",
    "        'isodate_calib' : isodate_midpoint,\n",
    "        'exposure_time': meteor_duration,\n",
    "        'astrometry_number_stars' : astrometry_number_stars,\n",
    "        #'photometric_zero_point': 0.0,\n",
    "        #'photometric_zero_point_uncertainty': 0.0,\n",
    "        'mag_label': 'mag',\n",
    "        'no_frags': 1,\n",
    "        'obs_az': getFloat(cfg['Center of plate Az']),     \n",
    "        'obs_ev': getFloat(cfg['Center of plate Alt']),     \n",
    "        'obs_rot': 0.0,   #float(cam_info['Cam tilt wrt Horiz (deg)']), # not in MetRec?   \n",
    "        'fov_horiz': float(cfg_fov[1]),     \n",
    "        'fov_vert': float(cfg_fov[2]),     \n",
    "    }\n",
    "    \n",
    "    # initialise table\n",
    "    ttt = Table()        \n",
    "    #Update the table metadata\n",
    "    ttt.meta.update(meta_dic) \n",
    "    \n",
    "    \n",
    "    # Meteor Info\n",
    "    # Datetime is ISO 8601 UTC format\n",
    "    metrec_index_array = []\n",
    "    datetime_array = []\n",
    "    azimuth_array  = [] # Azimuth are East of North, in degrees\n",
    "    altitude_array = [] # Altitudes are geometric (not apparent) angles above the horizon, in degrees\n",
    " \n",
    "    #right ascension and declination coordinates\n",
    "    ra_array  = []\n",
    "    dec_array = []    \n",
    "\n",
    "    x_array = []     \n",
    "    y_array = []      \n",
    "    mag_array = []  \n",
    "    \n",
    "    # start of J2000 epoch\n",
    "    ts = datetime.strptime(\"2000-01-01T12:00:00.000\",ISO_FORMAT)\n",
    "    start_epoch = datetime2JD(ts)\n",
    "\n",
    "\n",
    "    for i in range(len(inf['use'])):\n",
    "        if inf['use'][i] == True:\n",
    "            # time and location\n",
    "            metrec_index_array.append( i )\n",
    "            \n",
    "            temp_timestamp = inf['timestamp'][i]\n",
    "            temp_datetime  = datetime.strptime(temp_timestamp, ISO_FORMAT)\n",
    "\n",
    "            # RA is in hours, so multiply by 15\n",
    "            ra = 15 * float(inf['alpha'][i])\n",
    "            dec= float(inf['delta'][i])\n",
    "            \n",
    "            # RA and DEC are in J2000 epoch.  Precess to epoch of date, then convert to Az and Alt using RMS code\n",
    "            JD = datetime2JD(temp_datetime)\n",
    "            temp_ra, temp_dec = equatorialCoordPrecession(start_epoch, JD, ra, dec)  \n",
    "            temp_azim, temp_elev = raDec2AltAz(temp_ra, temp_dec, JD, obs_latitude, obs_longitude)\n",
    "\n",
    "            #right ascension and declination coordinates read, alt and az need to be calculated\n",
    "            temp_azim, temp_alt = raDec2AltAz(temp_ra, temp_dec, JD, obs_latitude, obs_longitude)\n",
    "            \n",
    "            datetime_array.append( temp_timestamp )\n",
    "            ra_array.append( ra  )\n",
    "            dec_array.append( dec )\n",
    "            azimuth_array.append( temp_azim )\n",
    "            altitude_array.append( temp_alt )  \n",
    "\n",
    "            x_array.append( float(inf['x'][i]) )\n",
    "            y_array.append( float(inf['y'][i]) )\n",
    "            \n",
    "            # astronomical magnitude of the brightness \n",
    "            if inf['bright'][i] == None :\n",
    "                mag_array.append( 99.9 ) \n",
    "            else:    \n",
    "                mag_array.append( float(inf['bright'][i]) ) \n",
    "\n",
    "    ## Populate the table with the data created to date\n",
    "    # create columns\n",
    "    ttt['datetime'] = datetime_array\n",
    "    ttt['ra']   = ra_array  * u.degree\n",
    "    ttt['dec']  = dec_array * u.degree    \n",
    "    ttt['azimuth']  = azimuth_array  * u.degree\n",
    "    ttt['altitude'] = altitude_array * u.degree    \n",
    "    ttt['mag']  =   mag_array\n",
    "    ttt['x_image']  = x_array\n",
    "    ttt['y_image']  = x_array\n",
    "\n",
    "    \n",
    "    return [ttt], 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Sky Cams functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_as7_stations(station_str):\n",
    "    # get a table of AllSky7 camera locations\n",
    "    # return the table, plus the index corresponding to \"station_str\"\n",
    "\n",
    "    stations_file_name = 'https://raw.githubusercontent.com/SCAMP99/scamp/master/ALLSKY7_location_list.csv'    \n",
    "\n",
    "    import requests\n",
    "    try:\n",
    "        r = requests.get(stations_file_name)\n",
    "        loc_table = ascii.read(r.text, delimiter=',')\n",
    "        print('Filling location table from online index')\n",
    "    except:\n",
    "        # create columns for the UK and ROI stations only. \n",
    "        # Station,City,Longitude,Latitude,Altitude,Firstlight,Operator\n",
    "        # AMS101,Birmingham Astronomical Society,-1.846419,52.408080,127,February 2021,Ben Stanley\n",
    "        # AMS100,Nuneaton,-1.45472222,52.52638889,80,December 2020,Ben Stanley\n",
    "        # AMS113,Galway,-9.089128,53.274739,31,January 2021,Charlie McCormack\n",
    "        \n",
    "        loc_table = Table()\n",
    "        loc_table['Station'] = 'AMS101','AMS100','AMS113'\n",
    "        loc_table['City'] = 'Birmingham Astronomical Society','Nuneaton','Galway'\n",
    "        loc_table['Longitude'] = '-1.846419','-1.45472222','-9.089128'\n",
    "        loc_table['Latitude'] = '52.40808','52.52638889','53.274739'\n",
    "        loc_table['Altitude'] = '127','80','31'\n",
    "        loc_table['Firstlight'] = 'Feb 2021','Dec 2020','Jan 2021'\n",
    "        loc_table['Operator'] = 'Ben Stanley','Ben Stanley','Charlie McCormack'\n",
    "        print('Filling location table from known locations')\n",
    "\n",
    "    no_stations = len(loc_table['Latitude'])\n",
    "\n",
    "    #The first key may have extra characters in it - if so, rename it.\n",
    "    for key_name in loc_table.keys(): \n",
    "        if 'Station' in key_name:\n",
    "            if not key_name == 'Station':\n",
    "                loc_table.rename_column(key_name,'Station')\n",
    "    \n",
    "    #print(loc_table)\n",
    "\n",
    "    i = -1\n",
    "    for j in range(no_stations):\n",
    "        if loc_table['Station'][j] == station_str:\n",
    "            i = j\n",
    "            break\n",
    "    \n",
    "    if i < 0:    \n",
    "        print('AllSky7 Station name \"' + station_str + '\" not found.') \n",
    "        return([], 0, i);\n",
    "    \n",
    "\n",
    "    print('AllSky7 Station name \"' + station_str + '\" is in row ',i) \n",
    "    return(loc_table, no_stations, i);\n",
    "\n",
    "\n",
    "\n",
    "def allskycams_to_std(json_data, lname):\n",
    "    # This reads a string which is in AllSkyCams json format and converts it to standard format\n",
    "\n",
    "    # Set up arrays for point observation data\n",
    "    datetime_array = []\n",
    "    datestr_array = []\n",
    "    azimuth_array = []\n",
    "    altitude_array = []\n",
    "    ra_array = []\n",
    "    dec_array = []\n",
    "    mag_array = []\n",
    "    x_image_array = []\n",
    "    y_image_array = []\n",
    "    \n",
    "\n",
    "    # Standard AllSky7 spec\n",
    "    instrument = 'NST-IPC16C91 - Low Lux SONY STARVIS Sensor Wireless IP Board Camera'\n",
    "    lens = '4 mm f/1.0'\n",
    "    cx = 1920\n",
    "    cy = 1080\n",
    "\n",
    "    \n",
    "    # Check the json data to see which format it is in, and extract information accordingly.  \n",
    "    \n",
    "    if 'station_name' in json_data :\n",
    "        # The February 2021 \"reduced.json\" format\n",
    "        # if lname.endswith(\"reduced.json\"):\n",
    "        \n",
    "        # for key_name in json_data.keys(): \n",
    "        #    print(key_name)\n",
    "        #\n",
    "        # api_key\n",
    "        # station_name\n",
    "        # device_name\n",
    "        # sd_video_file\n",
    "        # sd_stack\n",
    "        # hd_video_file\n",
    "        # hd_stack\n",
    "        # event_start_time\n",
    "        # event_duration\n",
    "        # peak_magnitude\n",
    "        # start_az\n",
    "        # start_el\n",
    "        # end_az\n",
    "        # end_el\n",
    "        # start_ra\n",
    "        # start_dec\n",
    "        # end_ra\n",
    "        # end_dec\n",
    "        # meteor_frame_data\n",
    "        # crop_box\n",
    "        # cal_params            \n",
    "        # \n",
    "        \n",
    "\n",
    "        no_lines = len(json_data['meteor_frame_data'])\n",
    "        #print('no_lines = ',no_lines)\n",
    "        #for k in range(no_lines):\n",
    "        #    print('\\n',json_data['meteor_frame_data'][k])\n",
    "        #    if k == 3 :\n",
    "        #        for m in range(len(json_data['meteor_frame_data'][k])):\n",
    "        #            print(\"json_data['meteor_frame_data'][\",k,\"][\",m,\"] = \",json_data['meteor_frame_data'][k][m])\n",
    "\n",
    "        for i in range(no_lines):\n",
    "            f_data = json_data['meteor_frame_data'][i]\n",
    "            #  \"meteor_frame_data\": [\n",
    "            #  [\n",
    "            #      [0] \"2021-02-04 05:42:07.800\",\n",
    "            #      [1] 46, fn\n",
    "            #      [2] 381, x\n",
    "            #      [3] 118, y\n",
    "            #      [4] 10, w\n",
    "            #      [5] 10, h\n",
    "            #      [6] 1275, [Number of pixels?]\n",
    "            #      [7] 348.38983647729816, RA\n",
    "            #      [8] 65.16531356859444, Dec\n",
    "            #      [9] 22.88795625855195, az\n",
    "            #      [10] 33.84381610533057, el\n",
    "            #   ],\n",
    "\n",
    "            date_str = f_data[0].replace(' ','T')\n",
    "            date_time = datetime.strptime(date_str,ISO_FORMAT)\n",
    "            #print('i=',i,' date_str =',date_str, ' date_time =',date_time)\n",
    "            datetime_array.append(date_time)\n",
    "            datestr_array.append(date_str)\n",
    "            azimuth_array.append(float(f_data[9]))\n",
    "            altitude_array.append(float(f_data[10]))\n",
    "            ra_array.append(float(f_data[7]))\n",
    "            dec_array.append(float(f_data[8]))\n",
    "            mag_array.append(0.0)\n",
    "            x_image_array.append(float(f_data[2]))\n",
    "            y_image_array.append(float(f_data[3]))\n",
    "        \n",
    "        meteor_duration = datetime_array[-1] - datetime_array[0]\n",
    "        print('meteor_duration = ', meteor_duration)\n",
    "        meteor_duration_float = float(meteor_duration.total_seconds())\n",
    "        frame_rate = (json_data['meteor_frame_data'][-1][1]- json_data['meteor_frame_data'][0][1]) / meteor_duration_float\n",
    "        print('frame_rate = ', frame_rate)\n",
    "    \n",
    "        time_step = (1 - json_data['meteor_frame_data'][0][1]) / frame_rate \n",
    "        isodate_start_time = datetime_array[0] + timedelta(seconds=time_step)\n",
    "        print('isodate_start_time = ', isodate_start_time)\n",
    "        isodate_end_time   = datetime_array[-1]\n",
    "        print('datetime_array[0] = ', datetime_array[0])\n",
    "        print('isodate_end_time = ', isodate_end_time)\n",
    "\n",
    "        isodate_midpoint_time = isodate_start_time + (isodate_end_time - isodate_start_time)/2\n",
    "        print('isodate_midpoint_time = ', isodate_midpoint_time)\n",
    "        isodate_start = isodate_start_time.strftime(ISO_FORMAT)   \n",
    "        isodate_end = isodate_end_time.strftime(ISO_FORMAT)   \n",
    "        isodate_midpoint = isodate_midpoint_time.strftime(ISO_FORMAT)   \n",
    "        \n",
    "        \n",
    "        print('\\n getting the list of AS7 stations, call 1')\n",
    "        station_str = json_data['station_name']\n",
    "        loc_table, no_stations, row_no = get_as7_stations(station_str)\n",
    "        #Station,City,Longitude,Latitude,Altitude,Firstlight,Operator\n",
    "        \n",
    "        if row_no < 0:   \n",
    "            # Station data is unavailable\n",
    "            # Put placeholders for station data\n",
    "            obs_latitude = -999.9  \n",
    "            obs_longitude = -999.9  \n",
    "            obs_elevation = -999.9  \n",
    "            location = 'Unknown'\n",
    "            telescope = 'Unknown'\n",
    "            camera_id = 'Unknown'\n",
    "            observer = 'Unknown'\n",
    "        else:\n",
    "            # Use the information from the lookup table\n",
    "            device_data = loc_table[row_no]\n",
    "            \n",
    "            obs_latitude = float(device_data['Latitude'])  \n",
    "            obs_longitude = float(device_data['Longitude'])  \n",
    "            obs_elevation = float(device_data['Altitude'])  \n",
    "            location = str(device_data['City'])\n",
    "            telescope = str(station_str)\n",
    "            camera_id = str(station_str)\n",
    "            observer = str(device_data['Operator'])\n",
    "        \n",
    "        device_data_internal = json_data['cal_params']\n",
    "        # \"cal_params\": {\n",
    "        #     \"center_az\": 291.03838531805667,\n",
    "        #     \"center_el\": 24.91924498460342,\n",
    "        #     \"position_angle\": 41.09621614877751,\n",
    "        #     \"pixscale\": 155.58669548833825,\n",
    "        #     \"ra_center\": \"22.498291666666667\",\n",
    "        #     \"dec_center\": \"32.03936111111111\",\n",
    "        #     \"user_stars\": [\n",
    "\n",
    "        rstars = len(device_data_internal['user_stars'])\n",
    "        \n",
    "        meta_dic = {'obs_latitude': obs_latitude,  \n",
    "           'obs_longitude': obs_longitude,  \n",
    "           'obs_elevation': obs_elevation,  \n",
    "           'origin': 'All Sky Systems',\n",
    "           'location': location,\n",
    "           'telescope': telescope,\n",
    "           'camera_id': camera_id,\n",
    "           'observer': observer,\n",
    "           'comment': '',            \n",
    "           'instrument': instrument,\n",
    "           'lens': lens,\n",
    "           'cx' : cx,     \n",
    "           'cy' : cy,     \n",
    "           'photometric_band' : 'Unknown',     \n",
    "           'image_file' : json_data['hd_video_file'],\n",
    "           'isodate_start_obs': str(isodate_start),  \n",
    "           'isodate_calib' : str(isodate_midpoint), \n",
    "           'exposure_time': meteor_duration_float,    \n",
    "           'astrometry_number_stars' : rstars,\n",
    "           #'photometric_zero_point': 0.0,    \n",
    "           #'photometric_zero_point_uncertainty': 0.0,\n",
    "           'mag_label': 'no_mag_data',     \n",
    "           'no_frags': 1,\n",
    "           'obs_az': float(device_data_internal['center_az']),     \n",
    "           'obs_ev': float(device_data_internal['center_el']),     \n",
    "           'obs_rot': 0.0,     \n",
    "           'fov_horiz': 0.0,     \n",
    "           'fov_vert': 0.0,     \n",
    "           }\n",
    "\n",
    "\n",
    "    elif 'best_meteor' in json_data :\n",
    "        # is the February 2021 format without station data\n",
    "        # includes the hacked form with manual dates, az, el \n",
    "        print(\"\\n the key 'best_meteor' is in the json data\")\n",
    "            \n",
    "        #for key_name in json_data.keys(): \n",
    "        #    print(key_name)\n",
    "        # sd_video_file\n",
    "        # sd_stack\n",
    "        # sd_objects\n",
    "        # hd_trim\n",
    "        # hd_stack\n",
    "        # hd_video_file\n",
    "        # hd_objects\n",
    "        # meteor\n",
    "        # cp\n",
    "        # best_meteor            \n",
    "        #         \n",
    "        # for key_name in json_data['best_meteor'].keys(): \n",
    "        #     print(key_name)\n",
    "        # \n",
    "        #     obj_id\n",
    "        #     ofns\n",
    "        #     oxs\n",
    "        #     oys\n",
    "        #     ows\n",
    "        #     ohs\n",
    "        #     oint\n",
    "        #     fs_dist\n",
    "        #     segs\n",
    "        #     report\n",
    "        #     ccxs\n",
    "        #     ccys\n",
    "        #     dt\n",
    "        #     ras\n",
    "        #     decs\n",
    "        #     azs\n",
    "        #     els            \n",
    "\n",
    "        no_lines = len(json_data['best_meteor']['dt'])\n",
    "        print('no_lines = ',no_lines)\n",
    "        file_hacked = ('ras' not in json_data['best_meteor'] )\n",
    "        print('file_hacked = ',file_hacked)\n",
    "\n",
    "        for i in range(no_lines):\n",
    "            date_str = (str(json_data['best_meteor']['dt'][i])).replace(' ','T')\n",
    "            date_time = datetime.strptime(date_str,ISO_FORMAT)\n",
    "            print('i=',i,' date_str=',date_str, ' date_time=',date_time)\n",
    "            datetime_array.append(date_time)\n",
    "            datestr_array.append(date_str)\n",
    "            azimuth_array.append(float(json_data['best_meteor']['azs'][i]))\n",
    "            altitude_array.append(float(json_data['best_meteor']['els'][i]))\n",
    "            if file_hacked :\n",
    "                x_image_array.append(0.0)\n",
    "                y_image_array.append(0.0)\n",
    "                # Do RA and DEC later\n",
    "            else:    \n",
    "                x_image_array.append(float(json_data['best_meteor']['ccxs'][i]))\n",
    "                y_image_array.append(float(json_data['best_meteor']['ccys'][i]))\n",
    "                ra_array.append(float(json_data['best_meteor']['ras'][i]))\n",
    "                dec_array.append(float(json_data['best_meteor']['decs'][i]))\n",
    "            mag_array.append(0.0)\n",
    "        \n",
    "        meteor_duration = datetime_array[-1] - datetime_array[0]\n",
    "        print('meteor_duration = ', meteor_duration)\n",
    "        meteor_duration_float = float(meteor_duration.total_seconds())\n",
    "        frame_rate = (json_data['best_meteor']['ofns'][-1]- json_data['best_meteor']['ofns'][0]) / meteor_duration_float\n",
    "        print('frame_rate = ', frame_rate)\n",
    "    \n",
    "        time_step = (1 - json_data['best_meteor']['ofns'][0]) / frame_rate \n",
    "        isodate_start_time = datetime_array[0] + timedelta(seconds=time_step)\n",
    "        print('isodate_start_time = ', isodate_start_time)\n",
    "        isodate_end_time   = datetime_array[-1]\n",
    "        print('datetime_array[0] = ', datetime_array[0])\n",
    "        print('isodate_end_time = ', isodate_end_time)\n",
    "\n",
    "        isodate_midpoint_time = isodate_start_time + (isodate_end_time - isodate_start_time)/2\n",
    "        print('isodate_midpoint_time = ', isodate_midpoint_time)\n",
    "        isodate_start = isodate_start_time.strftime(ISO_FORMAT)   \n",
    "        isodate_end = isodate_end_time.strftime(ISO_FORMAT)   \n",
    "        isodate_midpoint = isodate_midpoint_time.strftime(ISO_FORMAT)   \n",
    "        \n",
    "\n",
    "        # Now work out which station it is.  \n",
    "        # there is very little station info in the data file\n",
    "        station_str = ''\n",
    "        if 'archive_file' in json_data :\n",
    "            # The archive filename contains the station name\n",
    "            arch_str = str(json_data['archive_file'])\n",
    "            arch_list = arch_str.split('/')\n",
    "            for i in range (len(arch_list)):\n",
    "                if ('AMS' in arch_list[i]) and (not arch_list[i] == 'AMS2'):\n",
    "                    station_str = arch_list[i]\n",
    "                    break\n",
    "\n",
    "        if len(station_str) < 1:            \n",
    "            station_str = input(\"\\nWhich AllSky7 station is this data from (e.g. AMS100) :\")\n",
    "\n",
    "        if len(station_str) < 1:   \n",
    "            row_no = -1\n",
    "        else:    \n",
    "            print('\\n getting the list of AS7 stations, call 2')\n",
    "            loc_table, no_stations, row_no = get_as7_stations(station_str)\n",
    "            #Station,City,Longitude,Latitude,Altitude,Firstlight,Operator\n",
    "            \n",
    "        if row_no < 0:   \n",
    "            # Station data is unavailable\n",
    "            # Put placeholders for station data\n",
    "            obs_latitude = -999.9  \n",
    "            obs_longitude = -999.9  \n",
    "            obs_elevation = -999.9  \n",
    "            location = 'Unknown'\n",
    "            telescope = 'Unknown'\n",
    "            camera_id = 'Unknown'\n",
    "            observer = 'Unknown'\n",
    "        else:\n",
    "            # Use the information from the lookup table\n",
    "            device_data = loc_table[row_no]\n",
    "            \n",
    "            obs_latitude = float(device_data['Latitude'])  \n",
    "            obs_longitude = float(device_data['Longitude'])  \n",
    "            obs_elevation = float(device_data['Altitude'])  \n",
    "            location = str(device_data['City'])\n",
    "            telescope = str(station_str)\n",
    "            camera_id = str(station_str)\n",
    "            observer = str(device_data['Operator'])\n",
    "            \n",
    "            \n",
    "        device_data_internal = json_data['cp']\n",
    "        # \"cp\": {\n",
    "        #     \"center_az\": 345.6233888888889,\n",
    "        #     \"center_el\": 19.169500000000003,\n",
    "        #     \"position_angle\": 13.914659642573255,\n",
    "        #     \"pixscale\": 155.901484181,\n",
    "        #     \"ra_center\": \"310.7067083333333\",\n",
    "        #     \"dec_center\": \"54.69519444444444\",\n",
    "        #     \"user_stars\": [\n",
    "        #     [\n",
    "\n",
    "        \n",
    "        if file_hacked :\n",
    "            rstars = 0\n",
    "            comment = 'Reconstructed from basic az and alt data. No XY data'\n",
    "            # Now add RA and DEC\n",
    "        \n",
    "            # start of J2000 epoch\n",
    "            ts = datetime.strptime(\"2000-01-01T12:00:00.000\",ISO_FORMAT)\n",
    "            start_epoch = datetime2JD(ts)\n",
    "\n",
    "            for i in range(no_lines):\n",
    "                az   = float(azimuth_array[i])\n",
    "                elev = float(altitude_array[i])\n",
    "        \n",
    "                time_stamp = datestr_array[i]\n",
    "                ts = datetime.strptime(time_stamp,ISO_FORMAT)\n",
    "                JD = datetime2JD(ts)\n",
    "        \n",
    "                # USE Az and Alt to calculate correct RA and DEC in epoch of date, then precess back to J2000\n",
    "                temp_ra, temp_dec = altAz2RADec(az, elev, JD, obs_latitude, obs_longitude)\n",
    "                temp_ra, temp_dec = equatorialCoordPrecession(JD, start_epoch, temp_ra, temp_dec) \n",
    "                ra_array.append(temp_ra )\n",
    "                dec_array.append(temp_dec )        \n",
    "        else:    \n",
    "            rstars = len(device_data_internal['user_stars'])\n",
    "            comment = ''\n",
    "\n",
    "        \n",
    "        meta_dic = {'obs_latitude': obs_latitude,  \n",
    "           'obs_longitude': obs_longitude,  \n",
    "           'obs_elevation': obs_elevation,  \n",
    "           'origin': 'All Sky Systems',\n",
    "           'location': location,\n",
    "           'telescope': telescope,\n",
    "           'camera_id': camera_id,\n",
    "           'observer': observer,\n",
    "           'comment': comment,            \n",
    "           'instrument': instrument,\n",
    "           'lens': lens,\n",
    "           'cx' : cx,     \n",
    "           'cy' : cy,     \n",
    "           'photometric_band' : 'Unknown',     \n",
    "           'image_file' : json_data['hd_video_file'],\n",
    "           'isodate_start_obs': str(isodate_start),  \n",
    "           'isodate_calib' : str(isodate_midpoint), \n",
    "           'exposure_time': meteor_duration_float,    \n",
    "           'astrometry_number_stars' : rstars,\n",
    "           #'photometric_zero_point': 0.0,    \n",
    "           #'photometric_zero_point_uncertainty': 0.0,\n",
    "           'mag_label': 'no_mag_data',     \n",
    "           'no_frags': 1,\n",
    "           'obs_az': float(device_data_internal['center_az']),     \n",
    "           'obs_ev': float(device_data_internal['center_el']),     \n",
    "           'obs_rot': 0.0,     \n",
    "           'fov_horiz': 0.0,     \n",
    "           'fov_vert': 0.0,     \n",
    "           }\n",
    "            \n",
    "        \n",
    "    elif 'info' in json_data :\n",
    "        # is the July 2020 format\n",
    "        print('\\n July 2020 format')\n",
    "        for key_name in json_data.keys(): \n",
    "            print(key_name)\n",
    "        # info\n",
    "        # frames\n",
    "        # report\n",
    "        # sync\n",
    "        # calib \n",
    "\n",
    "        camera_id = json_data['info']['station']\n",
    "        location = str(json_data['info']['station'])\n",
    "        telescope = json_data['info']['device']\n",
    "        cx = int(json_data['calib']['img_dim'][0])     \n",
    "        cy = int(json_data['calib']['img_dim'][1])     \n",
    "        rstars = len(json_data['calib']['stars']) \n",
    "        no_lines = len(json_data['frames'])\n",
    "\n",
    "        # Work out who the observer was, if possible\n",
    "        loc_table, no_stations, row_no = get_as7_stations(camera_id)\n",
    "        #Station,City,Longitude,Latitude,Altitude,Firstlight,Operator\n",
    "        if row_no >= 0:\n",
    "            observer = str(loc_table[row_no]['Operator'])\n",
    "        else:\n",
    "            observer = location + ' ' + telescope\n",
    "\n",
    "        #print(\"\\n len(json_data['frames']) = \",no_lines)\n",
    "\n",
    "        for i in range(no_lines):\n",
    "            f_data = json_data['frames'][i]\n",
    "            #print(\"\\n json_data['frames'][\",i,\"] = \",f_data)\n",
    "            #json_data['frames'][ 4 ] =  {'fn': 57, 'x': 727, 'y': 667, 'w': 11, 'h': 11, 'dt': '2020-07-09 01:27:36.400', \n",
    "            #                             'az': 51.85325570513405, 'el': 31.17297922001948, 'ra': 317.34699971600514, \n",
    "            #                             'dec': 47.48858399651199}\n",
    "\n",
    "            date_str = f_data['dt'].replace(' ','T')\n",
    "            date_time = datetime.strptime(date_str,ISO_FORMAT)\n",
    "            #print('i=',i,' date_str =',date_str, ' date_time =',date_time)\n",
    "            datetime_array.append(date_time)\n",
    "            datestr_array.append(date_str)\n",
    "            azimuth_array.append(float(f_data['az']))\n",
    "            altitude_array.append(float(f_data['el']))\n",
    "            ra_array.append(float(f_data['ra']))\n",
    "            dec_array.append(float(f_data['dec']))\n",
    "            mag_array.append(0.0)\n",
    "            x_image_array.append(float(f_data['x']))\n",
    "            y_image_array.append(float(f_data['y']))\n",
    "\n",
    "        meteor_duration = datetime_array[-1] - datetime_array[0]\n",
    "        print('meteor_duration = ', meteor_duration)\n",
    "        meteor_duration_float = float(meteor_duration.total_seconds())\n",
    "        frame_rate = (json_data['frames'][-1]['fn']- json_data['frames'][0]['fn']) / meteor_duration_float\n",
    "        print('frame_rate = ', frame_rate)\n",
    "    \n",
    "        time_step = (1 - json_data['frames'][0]['fn']) / frame_rate \n",
    "        isodate_start_time = datetime_array[0] + timedelta(seconds=time_step)\n",
    "        print('isodate_start_time = ', isodate_start_time)\n",
    "        isodate_end_time   = datetime_array[-1]\n",
    "        print('datetime_array[0] = ', datetime_array[0])\n",
    "        print('isodate_end_time = ', isodate_end_time)\n",
    "\n",
    "        isodate_midpoint_time = isodate_start_time + (isodate_end_time - isodate_start_time)/2\n",
    "        print('isodate_midpoint_time = ', isodate_midpoint_time)\n",
    "        isodate_start = isodate_start_time.strftime(ISO_FORMAT)   \n",
    "        isodate_end = isodate_end_time.strftime(ISO_FORMAT)   \n",
    "        isodate_midpoint = isodate_midpoint_time.strftime(ISO_FORMAT)   \n",
    "\n",
    "        # construction of the metadata dictionary\n",
    "        device_data = json_data['calib']['device']                    \n",
    "        meta_dic = {'obs_latitude': float(device_data['lat']),  \n",
    "            'obs_longitude': float(device_data['lng']),  \n",
    "            'obs_elevation': float(device_data['alt']),  \n",
    "            'origin': 'All Sky Systems',\n",
    "            'location': location,\n",
    "            'telescope': telescope,\n",
    "            'camera_id': camera_id,\n",
    "            'observer': observer,\n",
    "            'comment': '',            \n",
    "            'instrument': instrument,\n",
    "            'lens': lens,\n",
    "            'cx' : cx,     \n",
    "            'cy' : cy,     \n",
    "            'photometric_band' : 'Unknown',     \n",
    "            'image_file' : json_data['info']['org_hd_vid'],\n",
    "            'isodate_start_obs': str(isodate_start),\n",
    "            'isodate_calib' : str(isodate_midpoint),\n",
    "            'exposure_time': meteor_duration_float,\n",
    "            'astrometry_number_stars' : rstars,\n",
    "            #'photometric_zero_point': 0.0,    \n",
    "            #'photometric_zero_point_uncertainty': 0.0,\n",
    "            'mag_label': 'no_mag_data',     \n",
    "            'no_frags': 1,\n",
    "            'obs_az': float(device_data['center']['az']),     \n",
    "            'obs_ev': float(device_data['center']['el']),     \n",
    "            'obs_rot': 0.0,     \n",
    "            'fov_horiz': 0.0,     \n",
    "            'fov_vert': 0.0,     \n",
    "            }\n",
    "    \n",
    "    else:        \n",
    "        print('\\n Json format not recognised')\n",
    "        return([], 0);\n",
    "        \n",
    "    \n",
    "    # initialise table\n",
    "    ttt = Table()        \n",
    "    #Update the table metadata\n",
    "    ttt.meta.update(meta_dic)   \n",
    "    \n",
    "    ttt['datetime'] = datestr_array\n",
    "    ttt['ra'] = ra_array\n",
    "    ttt['dec'] = dec_array\n",
    "    ttt['azimuth'] = azimuth_array\n",
    "    ttt['altitude'] = altitude_array\n",
    "    ttt['no_mag_data'] = mag_array\n",
    "    ttt['x_image'] = x_image_array\n",
    "    ttt['y_image'] = y_image_array\n",
    "    \n",
    "    return([ttt], 1);\n",
    "\n",
    "\n",
    "\n",
    "def std_to_allskycams(ttt):\n",
    "\n",
    "    info = {}\n",
    "    info['station'] = ttt.meta['location']   \n",
    "    info['device'] =  ttt.meta['telescope']    \n",
    "    info['org_hd_vid'] = ttt.meta['image_file']    \n",
    "\n",
    "    \n",
    "    # work out the frame rate of the observations in the table.  \n",
    "    # this code is long-form as it was copied across from the UFO conversion\n",
    "    start_time = Time(ttt['datetime'][0])  \n",
    "    start_time_str = str(ttt['datetime'][0])  \n",
    "    nlines = len(ttt['datetime'])    \n",
    "    cumu_times = []\n",
    "    step_sizes = []\n",
    "    last_sec = 0.0\n",
    "    for i in range(nlines):\n",
    "        sec = get_secs(Time(ttt['datetime'][i]),start_time)\n",
    "        cumu_times.append(sec)\n",
    "        sec_rounded = sec\n",
    "        time_change = int(round(1000*(sec_rounded - last_sec),0))\n",
    "        if i>0 and (time_change not in step_sizes):\n",
    "            step_sizes.append(time_change)\n",
    "        last_sec = sec_rounded\n",
    "    #now test for common framerates\n",
    "    # likely framerates are 20 (DFN), 25 (UFO) or 30 (FRIPON) fps\n",
    "    smallest = min(step_sizes)\n",
    "    if (smallest==33 or smallest == 34 or smallest == 66 or smallest == 67):\n",
    "        frame_rate = 30.0\n",
    "    elif (smallest >= 39 and smallest <= 41):\n",
    "        frame_rate = 25.0\n",
    "    elif (smallest >= 49 and smallest <= 51):\n",
    "        frame_rate = 20.0\n",
    "    else:\n",
    "        # non-standard framerate\n",
    "        # gcd is the greatest common divisor of all of the steps, in milliseconds.  \n",
    "        # Note - if gcd <= 10 it implies frame rate >= 100 fps, which is probably caused by a rounding error\n",
    "        gcd = array_gcd(step_sizes)\n",
    "        frame_rate = 1000.0/float(gcd)\n",
    "    frame_step = 1/frame_rate\n",
    "    #work out the head, tail and first frame number\n",
    "    head_sec = round(-get_secs(Time(ttt.meta['isodate_start_obs']),start_time),6)\n",
    "    head = int(round(head_sec / frame_step,0))\n",
    "    fs = head + 1\n",
    "    fN = 1+int(round(sec/frame_step,0))\n",
    "    fe = fs + fN -1\n",
    "    sN = nlines\n",
    "    sec = round(sec, 4)\n",
    "    \n",
    "    # work out number of frames-equivalent and tail\n",
    "    mid_sec = round(head_sec + get_secs(Time(ttt.meta['isodate_calib']),start_time),6)\n",
    "    clip_sec = round(max(min(2*mid_sec,30.0),(fe-1)*frame_step),6)   \n",
    "    no_frames = int(round(clip_sec/frame_step,0)) + 1\n",
    "    tail = max(0,no_frames - (head + fN))\n",
    "    no_frames = head + fN + tail\n",
    "    \n",
    "    frames = []\n",
    "    for i in range(nlines):\n",
    "        frame = {}\n",
    "        frame['fn'] = fs + int(round(cumu_times[i]/frame_step,0))\n",
    "        frame['x'] = int(round(ttt[i]['x_image'],0))\n",
    "        frame['y'] = int(round(ttt[i]['y_image'],0))\n",
    "        frame['w'] = 0\n",
    "        frame['h'] = 0\n",
    "        frame['dt'] = ttt[i]['datetime'].replace('T',' ')\n",
    "        frame['az'] = ttt[i]['azimuth']\n",
    "        frame['el'] = ttt[i]['altitude']\n",
    "        frame['ra'] = ttt[i]['ra']\n",
    "        frame['dec'] = ttt[i]['dec']\n",
    "        frames.append(frame)\n",
    "\n",
    "    center_dic = {}\n",
    "    center_dic['az'] = ttt.meta['obs_az']        \n",
    "    center_dic['el'] = ttt.meta['obs_ev']        \n",
    "\n",
    "    device = {}        \n",
    "    device['center'] = center_dic\n",
    "    device['alt'] = str(ttt.meta['obs_elevation'])\n",
    "    device['lat'] = str(ttt.meta['obs_latitude'])\n",
    "    device['lng'] = str(ttt.meta['obs_longitude'])\n",
    "\n",
    "    calib = {}\n",
    "    calib['device'] = device        \n",
    "    calib['img_dim'] = [ttt.meta['cx'], ttt.meta['cy']]  \n",
    "            \n",
    "    \n",
    "    # assemble a dictionary with the right data structure    \n",
    "    json_dict = {}\n",
    "    json_dict['info'] = info    \n",
    "    json_dict['frames'] = frames    \n",
    "    json_dict['calib'] = calib    \n",
    "\n",
    "    # convert the dictionary to a string \n",
    "    json_str = json.dumps(json_dict, ensure_ascii=True, indent=4)\n",
    "    \n",
    "    return json_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RA & DEC <==> Az Alt conversion, from RMS (c) Denis Vida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "A set of tools of working with meteor data. \n",
    "Includes:\n",
    "    - Julian date conversion\n",
    "    - LST calculation\n",
    "    - Coordinate transformations\n",
    "    - RA and Dec precession correction\n",
    "    - ...\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "# The MIT License\n",
    "\n",
    "# Copyright (c) 2016 Denis Vida\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "# THE SOFTWARE.\n",
    "\n",
    "import math\n",
    "from datetime import datetime, timedelta, MINYEAR\n",
    "\n",
    "\n",
    "### CONSTANTS ###\n",
    "\n",
    "# Define Julian epoch\n",
    "JULIAN_EPOCH = datetime(2000, 1, 1, 12) # noon (the epoch name is unrelated)\n",
    "J2000_JD = timedelta(2451545) # julian epoch in julian dates\n",
    "\n",
    "class EARTH_CONSTANTS(object):\n",
    "    \"\"\" Holds Earth's shape parameters. \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Earth elipsoid parameters in meters (source: IERS 2003)\n",
    "        self.EQUATORIAL_RADIUS = 6378136.6\n",
    "        self.POLAR_RADIUS = 6356751.9\n",
    "        self.RATIO = self.EQUATORIAL_RADIUS/self.POLAR_RADIUS\n",
    "        self.SQR_DIFF = self.EQUATORIAL_RADIUS**2 - self.POLAR_RADIUS**2\n",
    "\n",
    "# Initialize Earth shape constants object\n",
    "EARTH = EARTH_CONSTANTS()\n",
    "\n",
    "\n",
    "#################\n",
    "\n",
    "\n",
    "### Time conversions ###\n",
    "\n",
    "\n",
    "def JD2LST(julian_date, lon):\n",
    "    \"\"\" Convert Julian date to Local Sidreal Time and Greenwich Sidreal Time. \n",
    "    \n",
    "    Arguments;\n",
    "        julian_date: [float] decimal julian date, epoch J2000.0\n",
    "        lon: [float] longitude of the observer in degrees\n",
    "    \n",
    "    Return:\n",
    "        [tuple]: (LST, GST): [tuple of floats] a tuple of Local Sidreal Time and Greenwich Sidreal Time \n",
    "            (degrees)\n",
    "    \"\"\"\n",
    "\n",
    "    t = (julian_date - J2000_JD.days)/36525.0\n",
    "\n",
    "    # Greenwich Sidreal Time\n",
    "    GST = 280.46061837 + 360.98564736629 * (julian_date - 2451545) + 0.000387933 *t**2 - ((t**3) / 38710000)\n",
    "    GST = (GST+360) % 360\n",
    "\n",
    "    # Local Sidreal Time\n",
    "    LST = (GST + lon + 360) % 360\n",
    "    \n",
    "    return LST, GST\n",
    "\n",
    "\n",
    "def date2JD(year, month, day, hour, minute, second, millisecond=0, UT_corr=0.0):\n",
    "    \"\"\" Convert date and time to Julian Date with epoch J2000.0. \n",
    "    @param year: [int] year\n",
    "    @param month: [int] month\n",
    "    @param day: [int] day of the date\n",
    "    @param hour: [int] hours\n",
    "    @param minute: [int] minutes\n",
    "    @param second: [int] seconds\n",
    "    @param millisecond: [int] milliseconds (optional)\n",
    "    @param UT_corr: [float] UT correction in hours (difference from local time to UT)\n",
    "    @return :[float] julian date, epoch 2000.0\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert all input arguments to integer (except milliseconds)\n",
    "    year, month, day, hour, minute, second = map(int, (year, month, day, hour, minute, second))\n",
    "\n",
    "    # Create datetime object of current time\n",
    "    dt = datetime(year, month, day, hour, minute, second, int(millisecond*1000))\n",
    "\n",
    "    # Calculate Julian date\n",
    "    julian = dt - JULIAN_EPOCH + J2000_JD - timedelta(hours=UT_corr)\n",
    "    \n",
    "    # Convert seconds to day fractions\n",
    "    return julian.days + (julian.seconds + julian.microseconds/1000000.0)/86400.0\n",
    "\n",
    "\n",
    "\n",
    "def datetime2JD(dt, UT_corr=0.0):\n",
    "    \"\"\" Converts a datetime object to Julian date. \n",
    "    Arguments:\n",
    "        dt: [datetime object]\n",
    "    Keyword arguments:\n",
    "        UT_corr: [float] UT correction in hours (difference from local time to UT)\n",
    "    Return:\n",
    "        jd: [float] Julian date\n",
    "    \"\"\"\n",
    "\n",
    "    return date2JD(dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second, dt.microsecond/1000.0, \n",
    "        UT_corr=UT_corr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################\n",
    "\n",
    "\n",
    "### Spatial coordinates transformations ###\n",
    "\n",
    "def altAz2RADec(azim, elev, jd, lat, lon):\n",
    "    \"\"\" Convert azimuth and altitude in a given time and position on Earth to right ascension and \n",
    "        declination. \n",
    "    Arguments:\n",
    "        azim: [float] azimuth (+east of due north) in degrees\n",
    "        elev: [float] elevation above horizon in degrees\n",
    "        jd: [float] Julian date\n",
    "        lat: [float] latitude of the observer in degrees\n",
    "        lon: [float] longitde of the observer in degrees\n",
    "    Return:\n",
    "        (RA, dec): [tuple]\n",
    "            RA: [float] right ascension (degrees)\n",
    "            dec: [float] declination (degrees)\n",
    "    \"\"\"\n",
    "\n",
    "    azim = np.radians(azim)\n",
    "    elev = np.radians(elev)\n",
    "    lat = np.radians(lat)\n",
    "    lon = np.radians(lon)\n",
    "    \n",
    "    # Calculate hour angle\n",
    "    ha = np.arctan2(-np.sin(azim), np.tan(elev)*np.cos(lat) - np.cos(azim)*np.sin(lat))\n",
    "\n",
    "    # Calculate Local Sidereal Time\n",
    "    lst = np.radians(JD2LST(jd, np.degrees(lon))[0])\n",
    "    \n",
    "    # Calculate right ascension\n",
    "    ra = (lst - ha)%(2*np.pi)\n",
    "\n",
    "    # Calculate declination\n",
    "    dec = np.arcsin(np.sin(lat)*np.sin(elev) + np.cos(lat)*np.cos(elev)*np.cos(azim))\n",
    "\n",
    "    return np.degrees(ra), np.degrees(dec)\n",
    "\n",
    "def raDec2AltAz(ra, dec, jd, lat, lon):\n",
    "    \"\"\" Convert right ascension and declination to azimuth (+east of sue north) and altitude. \n",
    "    Arguments:\n",
    "        ra: [float] right ascension in degrees\n",
    "        dec: [float] declination in degrees\n",
    "        jd: [float] Julian date\n",
    "        lat: [float] latitude in degrees\n",
    "        lon: [float] longitude in degrees\n",
    "    Return:\n",
    "        (azim, elev): [tuple]\n",
    "            azim: [float] azimuth (+east of due north) in degrees\n",
    "            elev: [float] elevation above horizon in degrees\n",
    "        \"\"\"\n",
    "\n",
    "    ra = np.radians(ra)\n",
    "    dec = np.radians(dec)\n",
    "    lat = np.radians(lat)\n",
    "    lon = np.radians(lon)\n",
    "\n",
    "    # Calculate Local Sidereal Time\n",
    "    lst = np.radians(JD2LST(jd, np.degrees(lon))[0])\n",
    "\n",
    "    # Calculate the hour angle\n",
    "    ha = lst - ra\n",
    "\n",
    "    # Constrain the hour angle to [-pi, pi] range\n",
    "    ha = (ha + np.pi)%(2*np.pi) - np.pi\n",
    "\n",
    "    # Calculate the azimuth\n",
    "    azim = np.pi + np.arctan2(np.sin(ha), np.cos(ha)*np.sin(lat) - np.tan(dec)*np.cos(lat))\n",
    "\n",
    "    # Calculate the sine of elevation\n",
    "    sin_elev = np.sin(lat)*np.sin(dec) + np.cos(lat)*np.cos(dec)*np.cos(ha)\n",
    "\n",
    "    # Wrap the sine of elevation in the [-1, +1] range\n",
    "    sin_elev = (sin_elev + 1)%2 - 1\n",
    "\n",
    "    elev = np.arcsin(sin_elev)\n",
    "\n",
    "    return np.degrees(azim), np.degrees(elev)\n",
    "\n",
    "# use:\n",
    "# (ra, dec)    = altAz2RADec(azim, elev, datetime2JD(), lat, lon)\n",
    "# (azim, elev) = raDec2AltAz(azim, elev, datetime2JD(), lat, lon)\n",
    "\n",
    "\n",
    "# Vectorize the raDec2AltAz function so it can take numpy arrays for: ra, dec, jd\n",
    "raDec2AltAz_vect = np.vectorize(raDec2AltAz, excluded=['lat', 'lon'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Precession ###\n",
    "\n",
    "def equatorialCoordPrecession(start_epoch, final_epoch, ra, dec):\n",
    "    \"\"\" Corrects Right Ascension and Declination from one epoch to another, taking only precession into \n",
    "        account.\n",
    "        Implemented from: Jean Meeus - Astronomical Algorithms, 2nd edition, pages 134-135\n",
    "    @param start_epoch: [float] Julian date of the starting epoch\n",
    "    @param final_epoch: [float] Julian date of the final epoch\n",
    "    @param ra: [float] non-corrected right ascension in degrees\n",
    "    @param dec: [float] non-corrected declination in degrees\n",
    "    @return (ra, dec): [tuple of floats] precessed equatorial coordinates in degrees\n",
    "    \"\"\"\n",
    "\n",
    "    ra = math.radians(ra)\n",
    "    dec = math.radians(dec)\n",
    "\n",
    "    T = (start_epoch - 2451545) / 36525.0\n",
    "    t = (final_epoch - start_epoch) / 36525.0\n",
    "\n",
    "    # Calculate correction parameters\n",
    "    zeta  = ((2306.2181 + 1.39656*T - 0.000139*T**2)*t + (0.30188 - 0.000344*T)*t**2 + 0.017998*t**3)/3600\n",
    "    z     = ((2306.2181 + 1.39656*T - 0.000139*T**2)*t + (1.09468 + 0.000066*T)*t**2 + 0.018203*t**3)/3600\n",
    "    theta = ((2004.3109 - 0.85330*T - 0.000217*T**2)*t - (0.42665 + 0.000217*T)*t**2 - 0.041833*t**3)/3600\n",
    "\n",
    "    # Convert parameters to radians\n",
    "    zeta, z, theta = map(math.radians, (zeta, z, theta))\n",
    "\n",
    "    # Calculate the next set of parameters\n",
    "    A = math.cos(dec) * math.sin(ra + zeta)\n",
    "    B = math.cos(theta)*math.cos(dec)*math.cos(ra + zeta) - math.sin(theta)*math.sin(dec)\n",
    "    C = math.sin(theta)*math.cos(dec)*math.cos(ra + zeta) + math.cos(theta)*math.sin(dec)\n",
    "\n",
    "    # Calculate right ascension\n",
    "    ra_corr = math.atan2(A, B) + z\n",
    "\n",
    "    # Calculate declination (apply a different equation if close to the pole, closer then 0.5 degrees)\n",
    "    if (math.pi/2 - abs(dec)) < math.radians(0.5):\n",
    "        dec_corr = math.acos(math.sqrt(A**2 + B**2))\n",
    "    else:\n",
    "        dec_corr = math.asin(C)\n",
    "\n",
    "    temp_ra = math.degrees(ra_corr)    \n",
    "    if temp_ra < 0:\n",
    "        temp_ra += 360.\n",
    "\n",
    "    return temp_ra, math.degrees(dec_corr)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate UFO-style ra and dec by fitting a great circle\n",
    "def ufo_ra_dec_alt_az(ttt):\n",
    "    \n",
    "    # Compute times of first and last points\n",
    "    no_lines = len(ttt['datetime'])\n",
    "    try:\n",
    "        dt1 = datetime.strptime(str(ttt['datetime'][0]),ISO_FORMAT)\n",
    "        dt2 = datetime.strptime(str(ttt['datetime'][no_lines - 1]),ISO_FORMAT)\n",
    "    except:\n",
    "        dt1 = datetime.strptime(str(ttt['datetime'][0]),\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "        dt2 = datetime.strptime(str(ttt['datetime'][no_lines - 1]),\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    #JD = datetime2JD(dt1)\n",
    "\n",
    "        \n",
    "    ### Fit a great circle to Az/Alt measurements and compute model beg/end RA and Dec ###\n",
    "\n",
    "    # Convert the measurement Az/Alt to cartesian coordinates\n",
    "    # NOTE: All values that are used for Great Circle computation are:\n",
    "    #   theta - the zenith angle (90 deg - altitude)\n",
    "    #   phi - azimuth +N of due E, which is (90 deg - azim)\n",
    "    azim = ttt['azimuth']\n",
    "    elev = ttt['altitude']\n",
    "    x, y, z = polarToCartesian(np.radians((90 - azim)%360), np.radians(90 - elev))\n",
    "\n",
    "    # Fit a great circle\n",
    "    C, theta0, phi0 = fitGreatCircle(x, y, z)\n",
    "\n",
    "    # Get the first point on the great circle\n",
    "    phase1 = greatCirclePhase(np.radians(90 - elev[0]), np.radians((90 - azim[0])%360), \\\n",
    "        theta0, phi0)\n",
    "    alt1, azim1 = cartesianToPolar(*greatCircle(phase1, theta0, phi0))\n",
    "    alt1 = 90 - np.degrees(alt1)\n",
    "    azim1 = (90 - np.degrees(azim1))%360\n",
    "\n",
    "    # Get the last point on the great circle\n",
    "    phase2 = greatCirclePhase(np.radians(90 - elev[-1]), np.radians((90 - azim[-1])%360),\\\n",
    "        theta0, phi0)\n",
    "    aa, bb, cc = greatCircle(phase2, theta0, phi0)\n",
    "    alt2, azim2 = cartesianToPolar(aa, bb, cc)\n",
    "    alt2 = 90 - np.degrees(alt2)\n",
    "    azim2 = (90 - np.degrees(azim2))%360\n",
    "\n",
    "    # Compute RA/Dec from Alt/Az\n",
    "    obs_latitude = float(ttt.meta['obs_latitude'])\n",
    "    obs_longitude = float(ttt.meta['obs_longitude'])\n",
    "    ra1, dec1 = altAz2RADec(azim1, alt1, datetime2JD(dt1), obs_latitude, obs_longitude)\n",
    "    ra2, dec2 = altAz2RADec(azim2, alt2, datetime2JD(dt2), obs_latitude, obs_longitude)\n",
    "\n",
    "\n",
    "    return(float(alt1), float(alt2), float(azim1), float(azim2), float(ra1), float(ra2), float(dec1), float(dec2));\n",
    "\n",
    "\n",
    "\"\"\" Fitting a great circle to points in the Cartesian coordinates system. \"\"\"\n",
    "\n",
    "# The MIT License\n",
    "\n",
    "# Copyright (c) 2017, Denis Vida\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "# THE SOFTWARE.\n",
    "\n",
    "#from __future__ import print_function, division, absolute_import\n",
    "\n",
    "import scipy.linalg\n",
    "import scipy.optimize\n",
    "\n",
    "\n",
    "def greatCirclePhase(theta, phi, theta0, phi0):\n",
    "    \"\"\" Find the phase angle of the point closest to the given point on the great circle. \n",
    "    \n",
    "    Arguments:\n",
    "        theta: [float] Inclination of the point under consideration (radians).\n",
    "        phi: [float] Nodal angle of the point (radians).\n",
    "        theta0: [float] Inclination of the great circle (radians).\n",
    "        phi0: [float] Nodal angle of the great circle (radians).\n",
    "    Return:\n",
    "        [float] Phase angle on the great circle of the point under consideration (radians).\n",
    "    \"\"\"\n",
    "\n",
    "    def _pointDist(x):\n",
    "        \"\"\" Calculates the Cartesian distance from a point defined in polar coordinates, and a point on\n",
    "            a great circle. \"\"\"\n",
    "        \n",
    "        # Convert the pick to Cartesian coordinates\n",
    "        point = polarToCartesian(phi, theta)\n",
    "\n",
    "        # Get the point on the great circle\n",
    "        circle = greatCircle(x, theta0, phi0)\n",
    "\n",
    "        # Return the distance from the pick to the great circle\n",
    "        return np.sqrt((point[0] - circle[0])**2 + (point[1] - circle[1])**2 + (point[2] - circle[2])**2)\n",
    "\n",
    "    # Find the phase angle on the great circle which corresponds to the pick\n",
    "    res = scipy.optimize.minimize(_pointDist, 0)\n",
    "\n",
    "    return res.x\n",
    "\n",
    "\n",
    "\n",
    "def greatCircle(t, theta0, phi0):\n",
    "    \"\"\" \n",
    "    Calculates the point on a great circle defined my theta0 and phi0 in Cartesian coordinates. \n",
    "    \n",
    "    Sources:\n",
    "        - http://demonstrations.wolfram.com/ParametricEquationOfACircleIn3D/\n",
    "    Arguments:\n",
    "        t: [float or 1D ndarray] phase angle of the point in the great circle\n",
    "        theta0: [float] Inclination of the great circle (radians).\n",
    "        phi0: [float] Nodal angle of the great circle (radians).\n",
    "    Return:\n",
    "        [tuple or 2D ndarray] a tuple of (X, Y, Z) coordinates in 3D space (becomes a 2D ndarray if the input\n",
    "            parameter t is also a ndarray)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Calculate individual cartesian components of the great circle points\n",
    "    x = -np.cos(t)*np.sin(phi0) + np.sin(t)*np.cos(theta0)*np.cos(phi0)\n",
    "    y =  np.cos(t)*np.cos(phi0) + np.sin(t)*np.cos(theta0)*np.sin(phi0)\n",
    "    z =  np.sin(t)*np.sin(theta0)\n",
    "\n",
    "    return x, y, z\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fitGreatCircle(x, y, z):\n",
    "    \"\"\" Fits a great circle to points in 3D space. \n",
    "    Arguments:\n",
    "        x: [float] X coordiantes of points on the great circle.\n",
    "        y: [float] Y coordiantes of points on the great circle.\n",
    "        z: [float] Z coordiantes of points on the great circle.\n",
    "    Return: \n",
    "        X, theta0, phi0: [tuple of floats] Great circle parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Add (0, 0, 0) to the data, as the great circle should go through the origin\n",
    "    x = np.append(x, 0)\n",
    "    y = np.append(y, 0)\n",
    "    z = np.append(z, 0)\n",
    "\n",
    "    # Fit a linear plane through the data points\n",
    "    A = np.c_[x, y, np.ones(x.shape[0])]\n",
    "    C,_,_,_ = scipy.linalg.lstsq(A, z)\n",
    "\n",
    "    # Calculate the great circle parameters\n",
    "    z2 = C[0]**2 + C[1]**2\n",
    "\n",
    "    theta0 = np.arcsin(z2/np.sqrt(z2 + z2**2))\n",
    "    phi0 = np.arctan2(C[1], C[0])\n",
    "\n",
    "    return C, theta0, phi0\n",
    "    \n",
    "\n",
    "\n",
    "def cartesianToPolar(x, y, z):\n",
    "    \"\"\" Converts 3D cartesian coordinates to polar coordinates. \n",
    "    Arguments:\n",
    "        x: [float] Px coordinate.\n",
    "        y: [float] Py coordinate.\n",
    "        z: [float] Pz coordinate.\n",
    "    Return:\n",
    "        (theta, phi): [float] Polar angles in radians (inclination, azimuth).\n",
    "    \"\"\"\n",
    "\n",
    "    theta = np.arccos(z)\n",
    "    phi = np.arctan2(y, x)\n",
    "\n",
    "    return theta, phi\n",
    "\n",
    "\n",
    "\n",
    "def polarToCartesian(theta, phi):\n",
    "    \"\"\" Converts 3D spherical coordinates to 3D cartesian coordinates. \n",
    "    Arguments:\n",
    "        theta: [float] Inclination in radians.\n",
    "        phi: [float] Azimuth angle in radians.\n",
    "    Return:\n",
    "        (x, y, z): [tuple of floats] Coordinates of the point in 3D cartiesian coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    x = np.sin(phi)*np.cos(theta)\n",
    "    y = np.sin(phi)*np.sin(theta)\n",
    "    z = np.cos(phi)\n",
    "\n",
    "    return x, y, z\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general-purpose file-handling or numerical functions\n",
    "\n",
    "# GCD (or Highest Common Factor) of two numbers \n",
    "def find_gcd(x, y): \n",
    "    while(y): \n",
    "        x, y = y, x % y \n",
    "    return x \n",
    " \n",
    "    \n",
    "# GCD (or Highest Common Factor) of integers in an array \n",
    "def array_gcd(l): \n",
    "    len_array = len(l)\n",
    "    if len_array == 0:\n",
    "        return(0);\n",
    "    elif len_array == 1:\n",
    "        return(l[0]);\n",
    "    elif len_array == 2:\n",
    "        return(find_gcd(l[0],l[1]));\n",
    "    else:\n",
    "        gcd = find_gcd(l[0],l[1])\n",
    "        for i in range(2, len_array): \n",
    "            gcd = find_gcd(gcd, l[i]) \n",
    "        return(gcd);  \n",
    "\n",
    "    \n",
    "#get the number of seconds since start_time     \n",
    "def get_secs(ttt_date,start_time):     \n",
    "    head_days = Time(ttt_date)\n",
    "    head_days -= start_time\n",
    "    return(float(str(head_days))*24*60*60);    \n",
    "\n",
    "\n",
    "# define city fuction\n",
    "#def getcity(latlong):\n",
    "#    locator = Nominatim(user_agent=\"contact@ukfall.org.uk\",timeout = 10)\n",
    "#    rgeocode = RateLimiter(locator.reverse,min_delay_seconds = 0.001)\n",
    "#    try:\n",
    "#        location = rgeocode(latlong)\n",
    "#        di = dict(location.raw)\n",
    "#        if 'city' in di.keys():\n",
    "#            city = di['city']\n",
    "#        elif 'village' in di.keys():\n",
    "#            city = di['village']\n",
    "#        elif 'town' in di.keys():\n",
    "#            city = di['town']\n",
    "#        else:\n",
    "#            city = 'no city or town'\n",
    "#    except:\n",
    "#        city = 'city not found'\n",
    "#    return city # or return location.raw to see all the data\n",
    "\n",
    "\n",
    "def zipfilename(ttt_list, out_type):\n",
    "# returns a name for the zipped output file, e.g. 2020-12-31_UFO_EastBarnet.zip\n",
    "# ttt_list is a list of astropy tables, out_type is a string decribing the type of data written.\n",
    "\n",
    "    ttt = ttt_list[0]\n",
    "    location = ttt.meta['location']\n",
    "    no_meteors = len(ttt_list)\n",
    "    st = str(ttt['datetime'][0])\n",
    "\n",
    "    for k in range(no_meteors):\n",
    "        if ttt_list[k].meta['location'] != location:\n",
    "            location = 'MultiLocation'\n",
    "    \n",
    "    initial_file = st[0:10] + '_' + out_type + '_' + location[0:15] + '.zip'\n",
    "    # print('initial_file = ',initial_file)\n",
    "\n",
    "    return initial_file \n",
    "    \n",
    "   \n",
    "def outfilename(ttt_list, out_type, source, is_main, num_days, i):\n",
    "# returns a name for the output file, e.g. 2020-12-31_UFO_EastBarnet.zip\n",
    "# ttt is an astropy table, out_type is a string decribing the type of data written.\n",
    "# source is a string describing where the data came from.\n",
    "# is_main is True for the main data file, False for the ancillary (e.g. FRIPON location \n",
    "# or UFO csv summary) file. \n",
    "# \"num_days\" is used for the UFO CSV file name or is the the file number in DFN files.\n",
    "# 'i' is the index of the meteor.\n",
    "\n",
    "\n",
    "    ttt = ttt_list[i]\n",
    "    location = ttt.meta['location']\n",
    "    telescope = ttt.meta['telescope']\n",
    "    if out_type == 'UFO' and not is_main:\n",
    "        # check the name of the csv file\n",
    "        no_meteors = len(ttt_list)\n",
    "        for k in range(no_meteors):\n",
    "            if ttt_list[k].meta['location'] != location:\n",
    "                location = 'MultiLocation'\n",
    "            if ttt_list[k].meta['telescope'] != telescope:\n",
    "                telescope = 'MultiLocation'\n",
    "    location = location.replace(\" \", \"_\")[0:15]\n",
    "    telescope = telescope.replace(\" \", \"_\")[0:15]\n",
    "    if location == telescope:\n",
    "        telescope = ''\n",
    "    else:    \n",
    "        telescope = '_' + telescope\n",
    "\n",
    "        \n",
    "    if out_type == 'STD':\n",
    "        # Standard output, in form 2020-05-11T22_41_00_RMS_UK0002.ecsv.  \n",
    "        st = str(ttt['datetime'][0])  \n",
    "        output_file = st[0:19].replace(\":\", \"_\")\n",
    "        output_file += '_' + source + '_' \n",
    "        output_file += ttt.meta['camera_id'].replace(\" \", \"_\")[0:15]\n",
    "        output_file += '.ecsv' \n",
    "    \n",
    "    elif out_type == 'DFN' :\n",
    "        # Desert Fireball Network output\n",
    "        st = str(ttt['datetime'][0])  \n",
    "        output_file = str(num_days).zfill(3) + \"_\" + st[0:10] + '_'\n",
    "        output_file += st[11:13] + st[14:16] + st[17:19] + '_'\n",
    "        output_file += location + telescope + '.ecsv' \n",
    "    \n",
    "    elif out_type == 'UFO':\n",
    "        # UFOAnalyzer output files\n",
    "        if is_main :\n",
    "            # write the A.XML file in format : \"M20200601_220346_EastBarnet_NEA.XML\"\n",
    "            output_file = 'M' + isoStr(ttt['datetime'][0]).strftime('%Y%m%d_%H%M%S_') + \"00_\"\n",
    "            output_file += location + '_' + ttt.meta['camera_id'][0:2] + '_A.XML'\n",
    "        else:    \n",
    "            # name of the CSV file, e.g. 20201231_23_188_EastBarnet_NW.csv,\n",
    "            output_file = isoStr(ttt['datetime'][0]).strftime('%Y%m%d_%H_') + str(num_days).zfill(3) + \"_\"\n",
    "            output_file += location + '.csv'\n",
    "    \n",
    "    elif out_type == 'FRIPON':\n",
    "        # example 20200103T170201_UT_FRNO01_SJ.met\n",
    "        st = str(ttt['datetime'][0])  #e.g. 2020-01-03T17:02:01.885\n",
    "        output_file = st[0:4] + st[5:7]+ st[8:13]\n",
    "        output_file += st[14:16] + st[17:19] + '_UT' + telescope\n",
    "        if is_main :\n",
    "            output_file += '.met'\n",
    "        else:    \n",
    "            output_file += '_location.txt'\n",
    "            \n",
    "    else:\n",
    "        # A CSV file readable by Excel, or an ASC output file,\n",
    "        # plus a catch-all if file type unknown\n",
    "        st = str(ttt['datetime'][0]) #e.g. 2020-01-03T17:02:01.885\n",
    "        output_file =  st[0:10] + '_'\n",
    "        output_file += st[11:13] + st[14:16] + st[17:19] + '_'\n",
    "        if out_type == 'ASC':\n",
    "            output_file += location + telescope + '.json' \n",
    "        else:    \n",
    "            output_file += location + telescope + '.csv' \n",
    "    \n",
    "    return output_file \n",
    "\n",
    "\n",
    "def std_timeshift(ttt,sec):\n",
    "    # changes all of the dates in a standard table to make them earlier by a number of seconds equal to 'sec'    \n",
    "    \n",
    "    ttt.meta['isodate_start_obs'] = change_str_time(ttt.meta['isodate_start_obs'],sec) \n",
    "    ttt.meta['isodate_calib'] = change_str_time(ttt.meta['isodate_calib'],sec) \n",
    "    nlines = len(ttt['datetime'])    \n",
    "    for i in range(nlines):\n",
    "        ttt['datetime'][i] = change_str_time(ttt['datetime'][i],sec) \n",
    "    return ttt \n",
    "\n",
    "\n",
    "def change_str_time(in_str, sec):\n",
    "    # Takes an ISO datetime string, calculates a time earlier by 'sec', returning an ISO datetime string.\n",
    "    in_time = Time(in_str)\n",
    "    new_time = in_time + timedelta(seconds=-sec)\n",
    "    out_str = str(new_time)\n",
    "    return out_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nstarting program\\n\")\n",
    "\n",
    "file_read_types = ((\"all files\",\"*.*\"),(\"Standard\",\"*.ECSV\"),(\"UFOAnalyzer\",\"*A.XML\"),\\\n",
    "        (\"UKFN/DFN\",\"*.ECSV\"),(\"SCAMP/FRIPON\",\"*.MET\"),(\"SCAMP/FRIPON\",\"*.ZIP\"),(\"RMS/CAMS\",\"FTP*.txt\"),\\\n",
    "        (\"RMS/AllSkyCams\",\"*.json\"),(\"MetRec\",\"*.inf\"))\n",
    "_fname = filedialog.askopenfilename(multiple=False,title = \"Select file to read\",filetypes = file_read_types)\n",
    "\n",
    "if _fname == None or len(_fname) < 3:\n",
    "    sys.exit('User did not choose a file to open')\n",
    "\n",
    "lname = _fname.lower()\n",
    "print(\"Input data file chosen is: \",lname) \n",
    "initial_dir, file_name = os.path.split(_fname)\n",
    "\n",
    "\n",
    "if lname.endswith(\".ecsv\"):\n",
    "    # input is STANDARD or DFN\n",
    "    _obs_table = ascii.read(_fname, delimiter=',') \n",
    "    print(_obs_table)\n",
    "    \n",
    "    DFN_true = False\n",
    "    for key_name in _obs_table.meta.keys(): \n",
    "        if 'event_codename' in key_name: \n",
    "            DFN_true = True\n",
    "            \n",
    "    if  DFN_true :\n",
    "        print(\"DFN/UKFN format being read\")\n",
    "        ttt_list, meteor_count = dfn_to_std(_obs_table)\n",
    "        source = 'DFN'\n",
    "    else:    \n",
    "        print(\"standard format being read\")\n",
    "        ttt_list = [_obs_table]\n",
    "        meteor_count = 1\n",
    "        source = 'STD'\n",
    "        \n",
    "    \n",
    "elif lname.endswith(\"a.xml\"):\n",
    "    # input is UFOAnalyzer.  \n",
    "    print(\"UFO format being read\")\n",
    "    with open(_fname) as fd:\n",
    "        _obs_dic=xmltodict.parse(fd.read())\n",
    "    ttt_list, meteor_count = ufo_to_std(_obs_dic)\n",
    "    source = 'UFO'\n",
    "\n",
    "    \n",
    "elif lname.endswith(\".met\"):\n",
    "    # input is FRIPON/SCAMP\n",
    "    print(\"FRIPON/SCAMP format being read\")\n",
    "    source = 'FRIPON'\n",
    "    loc_table, no_stations = get_fripon_stations()\n",
    "    _obs_table = Table.read(_fname, format='ascii.sextractor')\n",
    "    ttt_list, meteor_count = fripon_to_std(_fname,_obs_table, loc_table, no_stations)\n",
    "\n",
    "    \n",
    "elif lname.endswith(\".zip\"):\n",
    "    # input is a FRIPON zipped results file usually containing multiple .met files\n",
    "    print(\"FRIPON zipped format being read\")\n",
    "\n",
    "    ttt_list = []\n",
    "    meteor_count = 0\n",
    "    source = 'FRIPON'\n",
    "    loc_table, no_stations = get_fripon_stations()\n",
    "    \n",
    "    # get the list of .met files\n",
    "    with ZipFile(lname, 'r') as zip: \n",
    "        for info in zip.infolist(): \n",
    "            if info.filename.endswith(\".met\"):\n",
    "                # extract, read and delete each \".met\" file\n",
    "                z_fname = zip.extract(info.filename)\n",
    "                _obs_table = Table.read(z_fname, format='ascii.sextractor')\n",
    "                os.remove(z_fname)\n",
    "                ttt_list2, meteor_count2 = fripon_to_std(z_fname,_obs_table, loc_table, no_stations)\n",
    "                if meteor_count2 > 0:\n",
    "                    meteor_count += meteor_count2\n",
    "                    ttt_list += ttt_list2\n",
    "\n",
    "     \n",
    "elif lname.endswith(\".txt\"):\n",
    "    # input is RMS or CAMS \n",
    "    meteor_text = open(_fname).read()\n",
    "    ttt_list = [] \n",
    "\n",
    "    # now check whether there is a platpars file in the same folder, i.e. input is RMS\n",
    "    _camera_file_path = os.path.join(initial_dir, 'platepars_all_recalibrated.json')\n",
    "    if not (os.path.exists( _camera_file_path)):\n",
    "        # no platpars file, so look for a CAL*.txt file \n",
    "        cal_files = []\n",
    "        all_files = os.listdir(initial_dir)\n",
    "        for file_name in all_files :\n",
    "            fname_low = file_name.lower() \n",
    "            if (fname_low.startswith('cal') and fname_low.endswith('.txt')): \n",
    "                cal_files.append(file_name)\n",
    "        if(len(cal_files) == 1 ):\n",
    "            # CAMS, one CAL file found\n",
    "            _camera_file_path = os.path.join(initial_dir, cal_files[0])\n",
    "        elif(len(cal_files) > 1 ):\n",
    "            # CAMS, multiple CAL files found\n",
    "            file_read_types = ((\"CAMS, CAL*.txt\",\"*.txt\"))\n",
    "            _camera_file_path = filedialog.askopenfilename(multiple=False,initialdir = initial_dir, initialfile=cal_files[0],title = \"Select one CAMS camera data file\", filetypes = file_read_types)\n",
    "        else:       \n",
    "            # no camera files found.  Ask the user for the RMS or CAMS camera metadata file name\n",
    "            file_read_types = ((\"all files\",\"*.*\"),(\"CAMS, CAL*.txt\",\"*.txt\"),(\"RMS, *.JSON\",\"*.json\"))\n",
    "            _camera_file_path = filedialog.askopenfilename(multiple=False,initialdir = initial_dir, title = \"Select an RMS or CAMS camera data file\", filetypes = file_read_types)\n",
    "    \n",
    "    if not _camera_file_path:\n",
    "        sys.exit(\"Camera Config not specified, exiting\")\n",
    "    if not (os.path.exists( _camera_file_path)):\n",
    "        sys.exit(\"Camera Config not found, exiting\")\n",
    "    _camera_lfile = _camera_file_path.lower()\n",
    "    print(\"Cam Data Path : \",_camera_lfile)\n",
    "\n",
    "    if _camera_lfile.endswith(\".json\"):\n",
    "        # Input is RMS\n",
    "        print(\"RMS format being read\")\n",
    "        rms_camera_data = rms_camera_json(_camera_file_path)\n",
    "        ttt_list, meteor_count =  rms_to_std(meteor_text,  rms_camera_data)\n",
    "        source = 'RMS'\n",
    "    elif _camera_lfile.endswith(\".txt\"):\n",
    "        # Input is CAMS\n",
    "        print(\"CAMS format being read\")\n",
    "        cams_camera_data = cams_camera_txt( _camera_file_path )\n",
    "        ttt_list, meteor_count = cams_to_std(meteor_text, cams_camera_data)\n",
    "        source = 'CAMS'\n",
    "    else:\n",
    "        sys.exit(\"Camera file not supported. Please supply a platepars JSON file (.json) for RMS, or a CAL TXT file (.txt) for CAMS\")\n",
    "\n",
    "        \n",
    "elif lname.endswith(\".json\"):\n",
    "    _json_str = open(_fname).read()\n",
    "    json_data = json.loads(_json_str)\n",
    "    if 'centroids' in json_data :  \n",
    "        # This is an RMS format\n",
    "        print(\"RMS .json format being read\")\n",
    "        source = 'RMS'\n",
    "        ttt_list, meteor_count = rms_json_to_std(json_data,lname)\n",
    "        \n",
    "    else:     \n",
    "        # input is AllSkyCams\n",
    "        print(\"AllSkyCams format being read\")\n",
    "        ttt_list, meteor_count = allskycams_to_std(json_data,lname)\n",
    "        source = 'ASC'\n",
    "    \n",
    "    \n",
    "elif lname.endswith(\".inf\"):\n",
    "    # Input is MetRec\n",
    "    # now look for the .log file    \n",
    "    print(\"MetRec format being read\")\n",
    "    log_files = []\n",
    "    all_files = os.listdir(initial_dir)\n",
    "    for file_name in all_files :\n",
    "        fname_low = file_name.lower() \n",
    "        if (fname_low.endswith('.log') and not(fname_low.startswith('mrg') or fname_low.startswith('states'))): \n",
    "            log_files.append(file_name)\n",
    "    if(len(log_files) == 1 ):\n",
    "        # one .log file found\n",
    "        _log_file_path = os.path.join(initial_dir, log_files[0])\n",
    "    else:\n",
    "        # Ask the user to choose the log file\n",
    "        file_read_types = ((\"MetRec log file\", \"*.log\"))\n",
    "        _log_file_path = filedialog.askopenfilename(multiple=False,initialdir = initial_dir, title = \"Select camera data file\", filetypes = file_read_types)\n",
    "    \n",
    "    print('MetRec log file used = ',_log_file_path)\n",
    "    inf = MetRecInfFile(_fname)\n",
    "    log = MetRecLogFile(_log_file_path)\n",
    "    \n",
    "    ttt_list, meteor_count = metrec_to_standard(inf, log)\n",
    "    source = 'MetRec'\n",
    "\n",
    "    \n",
    "    \n",
    "if meteor_count == 0:\n",
    "    sys.exit(\"No meteors detected - check file is correct\")\n",
    "else:\n",
    "    ttt = ttt_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of meteors read: \", meteor_count)\n",
    "output_type = int(input(\"\\nChoose output format: 1=Global Fireball Exchange (GFE), 2=UFO, 3=DFN/UKFN, 4=FRIPON, 5=AllSkyCams, 9=ExcelCSV :\"))\n",
    "print(\"You entered \" + str(output_type))\n",
    "\n",
    "# must make a 'file-like object' to allow astropy to write to zip ( ie: must have file.write(datastring) )\n",
    "class AstropyWriteZipFile:\n",
    "    def __init__(self, out_zip, out_file):\n",
    "        self.zip  = out_zip\n",
    "        self.at   = out_file\n",
    "        self.done = False\n",
    "            \n",
    "    def write(self, data):\n",
    "        if not self.done:\n",
    "            self.zip.writestr(self.at, data)\n",
    "            self.done = True\n",
    "            \n",
    "def isoStr(iso_datetime_string):\n",
    "     return datetime.strptime(iso_datetime_string, ISO_FORMAT)\n",
    "\n",
    "    \n",
    "# Write file(s) depending on input\n",
    "if (output_type<1 or output_type> 5) and not output_type==9:\n",
    "    sys.exit('Not valid input - it needed to be 1, 2, 3, 4, 5 or 9')\n",
    "\n",
    "elif output_type == 1 or output_type == 3:\n",
    "    #write Standard or DFN format\n",
    "    if output_type == 3:\n",
    "        out_type = 'DFN'\n",
    "    else:    \n",
    "        out_type = 'STD'\n",
    "    \n",
    "    if meteor_count > 1:\n",
    "        zip_file_init = zipfilename(ttt_list, out_type)\n",
    "        out_name = filedialog.asksaveasfilename(initialdir=initial_dir,initialfile=zip_file_init,title = \"Save file\")\n",
    "        # zipset = {}\n",
    "        if out_name:\n",
    "            output_zip = ZipFile(out_name, mode='w')\n",
    "            for i in range (meteor_count):\n",
    "                if output_type == 3:\n",
    "                    ttt = std_to_dfn(ttt_list[i])\n",
    "                else:     \n",
    "                    ttt = ttt_list[i]\n",
    "                out_name2 = outfilename(ttt_list, out_type, source, True, 0, i)\n",
    "                ascii.write(ttt, AstropyWriteZipFile(output_zip, out_name2), format='ecsv', delimiter=',')\n",
    "            output_zip.close()\n",
    "            print(\"Zip file written: \", out_name)\n",
    "    else: \n",
    "        # write output to a single file\n",
    "        initial_file = outfilename(ttt_list, out_type, source, True, 0, 0)\n",
    "        out_name = filedialog.asksaveasfilename(initialdir=initial_dir,initialfile=initial_file,title = \"Save file\")\n",
    "        if out_name :\n",
    "            if output_type == 3:\n",
    "                ttt = std_to_dfn(ttt_list[0])\n",
    "            else:     \n",
    "                ttt = ttt_list[0]\n",
    "            ttt.write(out_name,overwrite=True, format='ascii.ecsv', delimiter=',')\n",
    "            print(\"Data file written: \", out_name)\n",
    "\n",
    "            \n",
    "elif output_type == 2:\n",
    "    # UFOAnalyzer output - always written to a zip file    \n",
    "    zip_file_init = zipfilename(ttt_list, 'UFO')\n",
    "    zip_file_name = filedialog.asksaveasfilename(initialdir = initial_dir,initialfile=zip_file_init,title = \"Select file\",defaultextension = '.csv')\n",
    "    if zip_file_name :\n",
    "        output_zip     = ZipFile(zip_file_name, mode='w')\n",
    "        output_csv_str = \"\"\n",
    "        for i in range(len(ttt_list)):\n",
    "            ttt = ttt_list[i]\n",
    "            #converts to 2 strings - the XML file and one line from the CSV file\n",
    "            ufo_xml_data, ufo_csv_line = std_to_ufo(ttt)\n",
    "            out_name2 = outfilename(ttt_list, 'UFO', source, True, 0, i)\n",
    "            output_zip.writestr(out_name2, ufo_xml_data)\n",
    "            if i == 0:\n",
    "                output_csv_string = ufo_csv_line\n",
    "            else:\n",
    "                output_csv_string += '\\n' + ufo_csv_line.split('\\n')[1]\n",
    "                \n",
    "        #difference in days:\n",
    "        num_days = ( isoStr(ttt_list[-1]['datetime'][0]) - isoStr(ttt_list[0]['datetime'][0]) ).days\n",
    "        out_csv_file = outfilename(ttt_list, 'UFO', source, False, num_days, 0)\n",
    "        output_zip.writestr(out_csv_file, output_csv_string)\n",
    "        output_zip.close()\n",
    "        print(\"Zip file written: \", zip_file_name)\n",
    "        \n",
    "        \n",
    "elif output_type == 4:\n",
    "    # write a file in FRIPON/SCAMP format\n",
    "    zip_file_init = zipfilename(ttt_list, 'FRIPON')\n",
    "    zip_file_name = filedialog.asksaveasfilename(initialdir = initial_dir,initialfile=zip_file_init,title = \"Select file\",defaultextension = '.csv')\n",
    "        \n",
    "    if zip_file_name :\n",
    "        output_zip     = ZipFile(zip_file_name, mode='w')\n",
    "        for i in range(len(ttt_list)):\n",
    "            ttt = ttt_list[i]\n",
    "            ttt2 = std_to_fripon(ttt)\n",
    "            fri_str, loc_str = fripon_write(ttt2)\n",
    "            out_name2 = outfilename(ttt_list, 'FRIPON', source, True, 0, i)\n",
    "            output_zip.writestr(out_name2, fri_str)                \n",
    "            out_name2 = outfilename(ttt_list, 'FRIPON', source, False, 0, i)\n",
    "            output_zip.writestr(out_name2, loc_str)                \n",
    "        output_zip.close()\n",
    "        print(\"Zip file written: \", zip_file_name)\n",
    " \n",
    "\n",
    "\n",
    "elif output_type == 5:\n",
    "    #write AllSkyCams format\n",
    "    if meteor_count > 1:\n",
    "        zip_file_init = zipfilename(ttt_list, 'ASC')\n",
    "        zip_file_name = filedialog.asksaveasfilename(initialdir = initial_dir,initialfile=zip_file_init,title = \"Select file\",defaultextension = '.csv')\n",
    "        \n",
    "        if zip_file_name :\n",
    "            output_zip     = ZipFile(zip_file_name, mode='w')\n",
    "            for i in range(len(ttt_list)):\n",
    "                ttt = ttt_list[i]\n",
    "                json_str = std_to_allskycams(ttt)\n",
    "                out_name2 = outfilename(ttt_list, 'ASC', source, True, 0, i)\n",
    "                output_zip.writestr(out_name2, json_str)                \n",
    "            output_zip.close()\n",
    "            print(\"Zip file written: \", zip_file_name)\n",
    "    else: \n",
    "        # write AllSkyCams data to a single file\n",
    "        ttt = ttt_list[0]\n",
    "        initial_file = outfilename(ttt_list, 'ASC', source, True, 0, 0)\n",
    "        out_name = filedialog.asksaveasfilename(initialdir=initial_dir,initialfile=initial_file,title = \"Save file\")\n",
    "        if out_name :\n",
    "            # write json_str to a file called out_name\n",
    "            json_str = std_to_allskycams(ttt)\n",
    "            out_file = open(out_name, \"w\")\n",
    "            out_file.write(json_str)\n",
    "            out_file.flush()\n",
    "            out_file.close()\n",
    "            print(\"Data file written: \", out_name)\n",
    "\n",
    "            \n",
    "elif output_type == 9:\n",
    "    #write Excel csv format\n",
    "    if meteor_count > 1:\n",
    "        zip_file_init = zipfilename(ttt_list, 'CSV')\n",
    "        zip_file_name = filedialog.asksaveasfilename(initialdir = initial_dir,initialfile=zip_file_init,title = \"Select file\",defaultextension = '.csv')\n",
    "        \n",
    "        if zip_file_name :\n",
    "            output_zip     = ZipFile(zip_file_name, mode='w')\n",
    "            for i in range(len(ttt_list)):\n",
    "                ttt = ttt_list[i]\n",
    "                csv_str = std_to_csv(ttt)\n",
    "                out_name2 = outfilename(ttt_list, 'CSV', source, True, 0, i)\n",
    "                output_zip.writestr(out_name2, csv_str)                \n",
    "            output_zip.close()\n",
    "            print(\"Zip file written: \", zip_file_name)\n",
    "    else: \n",
    "        # write Excel csv data to a single file\n",
    "        ttt = ttt_list[0]\n",
    "        initial_file = outfilename(ttt_list, 'CSV', source, True, 0, 0)\n",
    "        out_name = filedialog.asksaveasfilename(initialdir=initial_dir,initialfile=initial_file,title = \"Save file\")\n",
    "        if out_name :\n",
    "            # write csv_str to a file called out_name\n",
    "            csv_str = std_to_csv(ttt)\n",
    "            out_file = open(out_name, \"w\")\n",
    "            out_file.write(csv_str)\n",
    "            out_file.flush()\n",
    "            out_file.close()\n",
    "            print(\"Data file written: \", out_name)\n",
    "\n",
    "\n",
    "else:        \n",
    "     print('Invalid output type chosen (',output_type,')')\n",
    "\n",
    "        \n",
    "print('finished')  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
